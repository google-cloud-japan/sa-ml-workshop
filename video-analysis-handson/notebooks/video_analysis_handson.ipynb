{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "76fe99b8-22e6-4519-8126-cc9f423bab85",
   "metadata": {},
   "source": [
    "# Gemini API とオープンソースによる動画処理・動画分析の手法"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4a8464f-254b-455f-8d85-d9f3144d4a43",
   "metadata": {},
   "source": [
    "このハンズオンでは、Gemini による動画分析に加えて、オープンソースを利用した動画処理の手法を学びます。\n",
    "\n",
    "具体的には、次のオープンソースを用いて、動画の前処理と動体検知を行います。\n",
    "\n",
    "- moviepy：動画の前処理（タイムコードの焼きつけとファイルサイズの調整）\n",
    "- opencv：動体検知（動きのある区間の検出）\n",
    "\n",
    "その後、動きの無い区間と動きのある区間を個別に Gemini API で分析します。\n",
    "\n",
    "動きの無い区間は動画ファイルの代わりに、区間の開始時点・終了時点の静止画のみを用いることで、Gemini API に入力するトークン数を減らして分析時間を短縮します。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbb36291-1673-45fb-bb5f-781f59c54e87",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 事前準備"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9022fee-abaf-4d24-8e1e-2a1e83a7bcc6",
   "metadata": {},
   "source": [
    "### パッケージインストール"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a49b2e1-57ff-4e08-b8df-4d5a0016d188",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%pip install \\\n",
    "    opencv-python==4.11.0.86 \\\n",
    "    moviepy==2.1.2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b95ee645-4f64-4852-aa82-03ed59f7516f",
   "metadata": {
    "tags": []
   },
   "source": [
    "インストールしたパッケージを利用可能にするためにカーネルを再起動します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "71371410-d224-4f40-910f-eaa202cc8867",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import IPython\n",
    "app = IPython.Application.instance()\n",
    "_ = app.kernel.do_shutdown(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64c6dbe1-8698-4522-929f-9f103b39595c",
   "metadata": {},
   "source": [
    "### モジュールのインポートと初期設定"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3b3ea6c2-712a-4c07-b793-1ff45328e4a0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import copy, json, os, pprint, tempfile, threading, time, uuid\n",
    "import cv2\n",
    "from datetime import datetime, timedelta\n",
    "from tqdm.notebook import tqdm\n",
    "from IPython.display import Video\n",
    "from moviepy import VideoFileClip, TextClip, CompositeVideoClip, VideoClip, ColorClip\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import matplotlib.patches as patches\n",
    "\n",
    "from google.cloud import storage\n",
    "\n",
    "import vertexai\n",
    "from google import genai\n",
    "from google.genai.types import (\n",
    "    HttpOptions, GenerateContentConfig, Part, Content\n",
    ")\n",
    "\n",
    "[PROJECT_ID] = !gcloud config list --format 'value(core.project)'\n",
    "LOCATION = 'us-central1'\n",
    "\n",
    "vertexai.init(\n",
    "    project=PROJECT_ID,\n",
    "    location=LOCATION,\n",
    ")\n",
    "\n",
    "BUCKET_NAME = f'{PROJECT_ID}_video_files'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afce8b8f-a4a3-40ca-93ce-114056331933",
   "metadata": {},
   "source": [
    "### ストレージバケット作成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c0e086ac-a7e7-4fb0-9bdf-9dc48f299caf",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating gs://etsuji-handson01_video_files/...\n"
     ]
    }
   ],
   "source": [
    "result = !gsutil ls gs://{BUCKET_NAME}\n",
    "if result and result[0].startswith('BucketNotFoundException'):\n",
    "    !gsutil mb -b on -l {LOCATION} gs://{BUCKET_NAME}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa849601-13bc-41a6-a20f-1e373dbebfaf",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 補助関数の定義"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08e4aec6-643e-48ac-ba9f-50f63b56740a",
   "metadata": {
    "tags": []
   },
   "source": [
    "### ファイルをストレージバケットにアップロード・ダウンロードする関数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "678c9b20-97ef-4d4f-b5dd-e50c3e3b127d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def upload_blob(source_path, destination_path, bucket_name=BUCKET_NAME):\n",
    "    storage_client = storage.Client()\n",
    "    bucket = storage_client.bucket(bucket_name)\n",
    "    blob = bucket.blob(destination_path)\n",
    "    blob.upload_from_filename(source_path)\n",
    "\n",
    "def download_blob(source_path, destination_path, bucket_name=BUCKET_NAME): \n",
    "    storage_client = storage.Client()\n",
    "    bucket = storage_client.bucket(bucket_name)\n",
    "    blob = bucket.blob(source_path)\n",
    "    blob.download_to_filename(destination_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bd68e8f-815c-46ce-b88f-15e40fab42f8",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Gemini API でコンテンツを分析する関数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "838b6d48-1b42-42e4-bbc6-045ee0ceb69c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def analyze_content(system_instruction, contents,\n",
    "                    response_schema, temperature=0.1,\n",
    "                    model='gemini-2.5-flash'):\n",
    "    client = genai.Client(vertexai=True,\n",
    "                          project=PROJECT_ID, location=LOCATION,\n",
    "                          http_options=HttpOptions(api_version='v1'))\n",
    "    response = client.models.generate_content(\n",
    "        model=model,\n",
    "        contents=contents,\n",
    "        config=GenerateContentConfig(\n",
    "            system_instruction=system_instruction,\n",
    "            temperature=temperature,\n",
    "            top_p=0.5,\n",
    "            response_mime_type='application/json',\n",
    "            response_schema=response_schema,\n",
    "        )\n",
    "    )\n",
    "    result_text = '\\n'.join(\n",
    "        [p.text for p in response.candidates[0].content.parts if p.text]\n",
    "    )\n",
    "    return json.loads(result_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f2ab1f8-1022-4288-9734-5cc30cb09e99",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 動体検知の結果をヒートマップにビジュアライズする関数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a9dd5d67-be5e-4ec3-bd45-8fd705082006",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def show_heatmap(active_rate, event_list):\n",
    "    base_time = event_list[0]['start_time']\n",
    "    unusual_periods = []\n",
    "    for event in event_list:\n",
    "        if event['status'] == 'unusual':\n",
    "            start_time = event['start_time'] - base_time\n",
    "            end_time = event['end_time'] - base_time\n",
    "            unusual_periods.append((start_time, end_time))\n",
    "\n",
    "    original_data = np.array(active_rate)\n",
    "    smooth_length = 400\n",
    "    x_original = np.linspace(0, 1, len(original_data))\n",
    "    x_smooth = np.linspace(0, 1, smooth_length)\n",
    "    data_smooth = np.interp(x_smooth, x_original, original_data)\n",
    "    data_2d = data_smooth.reshape(1, -1)\n",
    "\n",
    "    plt.figure(figsize=(10, 0.5))\n",
    "    ax = plt.gca()\n",
    "    sns.heatmap(data_2d, annot=False, cmap='Blues', vmax=100, cbar=False)#, fmt='d')\n",
    "    plt.yticks([])\n",
    "    plt.ylabel('')\n",
    "    plt.xticks([])\n",
    "    plt.xlabel('')    \n",
    "    tick_positions = np.linspace(0, smooth_length - 1, num=len(original_data))\n",
    "    for (start_time, end_time) in unusual_periods:\n",
    "        x1 = tick_positions[start_time]\n",
    "        x2 = tick_positions[end_time]\n",
    "        box_width = x2 - x1\n",
    "        rect = patches.Rectangle(\n",
    "            (x1, 0), box_width, 0.95,\n",
    "            linewidth=2, edgecolor='red', facecolor='none'\n",
    "        )\n",
    "        ax.add_patch(rect)\n",
    "    plt.xticks(ticks=tick_positions, labels=np.arange(len(original_data)))\n",
    "    plt.xlabel('Seconds')\n",
    "    return unusual_periods"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fea461d-1c00-4253-bd7f-6c8ea1a6c02c",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 動画の前処理"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69673f19-3ca3-41b7-8998-23c0072fe83e",
   "metadata": {},
   "source": [
    "動画にタイムコードを焼き付けて、ファイルサイズを圧縮します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c2de4108-264b-47a9-ac9c-a4399050d441",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def add_timestamp_overlay(\n",
    "    video_path,\n",
    "    output_path,\n",
    "    video_start_time='2025-01-01 00:00:00', \n",
    "):\n",
    "    with tempfile.TemporaryDirectory() as temp_dir:\n",
    "\n",
    "        video_source = os.path.join(temp_dir, video_path)\n",
    "        video_dest = os.path.join(temp_dir, output_path)\n",
    "\n",
    "        dirname, _ = os.path.split(video_source)\n",
    "        if dirname:\n",
    "            os.makedirs(dirname, exist_ok=True)\n",
    "        dirname, _ = os.path.split(video_dest)\n",
    "        if dirname:\n",
    "            os.makedirs(dirname, exist_ok=True)\n",
    "\n",
    "        download_blob(video_path, video_source)\n",
    "\n",
    "        # Parse the start time\n",
    "        start_time = datetime.strptime(\n",
    "            video_start_time, '%Y-%m-%d %H:%M:%S'\n",
    "        )\n",
    "\n",
    "        # Load video and resize it\n",
    "        video = VideoFileClip(video_source).resized(width=640)\n",
    "\n",
    "        # Background of timecode area\n",
    "        bg_clip = (\n",
    "            ColorClip(\n",
    "            size=(225, 38),   # Timecode area size\n",
    "            color=(0, 0, 0),  # Black color\n",
    "                duration=video.duration,\n",
    "            )\n",
    "            .with_opacity(0.5)\n",
    "            .with_position(('left', 'top'))\n",
    "        )\n",
    "\n",
    "        # Timecode clips\n",
    "        text_clips = []\n",
    "        total_seconds = int(video.duration)\n",
    "\n",
    "        for i in range(total_seconds + 1):\n",
    "            current_time = start_time + timedelta(seconds=i)\n",
    "            timestamp_text = current_time.strftime('%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "            clip_duration = 1.0\n",
    "            if i == total_seconds: # Last clip might be shorter\n",
    "                clip_duration = video.duration - total_seconds\n",
    "                if clip_duration <= 0:\n",
    "                    continue\n",
    "\n",
    "            txt = (\n",
    "                TextClip(\n",
    "                    text=timestamp_text,\n",
    "                    font_size=19,\n",
    "                    color='white',\n",
    "                    font='DejaVuSans',\n",
    "                    method='label',\n",
    "               )\n",
    "               .with_duration(clip_duration)\n",
    "               .with_start(i)\n",
    "               .with_position((10, 12))\n",
    "            )\n",
    "            text_clips.append(txt)\n",
    "\n",
    "        # Merge all clips\n",
    "        all_clips = [video, bg_clip] + text_clips\n",
    "        final_video = CompositeVideoClip(all_clips)\n",
    "\n",
    "        # Write the result with optimized settings\n",
    "        if video.audio is None:\n",
    "            final_video.write_videofile(\n",
    "                video_dest,\n",
    "                codec='libx264',\n",
    "                preset='faster',\n",
    "                threads=os.cpu_count(),\n",
    "                audio=False,\n",
    "                remove_temp=True,\n",
    "                # logger=None,  # Suppress moviepy's verbose output\n",
    "            )\n",
    "        else:\n",
    "            final_video.write_videofile(\n",
    "                video_dest,\n",
    "                codec='libx264',\n",
    "                preset='faster',\n",
    "                threads=os.cpu_count(),\n",
    "                audio_codec='libmp3lame',\n",
    "                # temp_audiofile should be in temp_dir\n",
    "                temp_audiofile=os.path.join(temp_dir, 'temp-audio.mp3'),\n",
    "                remove_temp=True,\n",
    "                # logger=None,  # Suppress moviepy's verbose output\n",
    "            )\n",
    "\n",
    "        upload_blob(video_dest, output_path)\n",
    "        \n",
    "        # Cleanup\n",
    "        for item in all_clips:\n",
    "            item.close()\n",
    "        final_video.close()\n",
    "\n",
    "    return video_start_time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c57c4b2f-3a72-4990-9a79-bb2d8b5206c1",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 実行例"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3039b939-a206-411c-9c70-0e435a15bbfc",
   "metadata": {},
   "source": [
    "GitHub から動画サンプルを取得して、ストレージバケットに保存します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "eac1514d-29ed-46ce-88b8-2991b2e61470",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!wget -q -O room_camera_example.mov \\\n",
    "https://raw.githubusercontent.com/google-cloud-japan/sa-ml-workshop/main/video-analysis-handson/movie_files/room_camera_example.mov\n",
    "upload_blob('room_camera_example.mov', 'original/room_camera_example.mov')\n",
    "!rm room_camera_example.mov"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cee549c6-7b6c-451e-b777-97e53301d57f",
   "metadata": {
    "tags": []
   },
   "source": [
    "ストレージバケットに保存した動画に前処理を適用します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e777c570-8847-4cd1-a8e6-8cef798195e0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'video_found': True, 'audio_found': True, 'metadata': {'major_brand': 'qt', 'minor_version': '0', 'compatible_brands': 'qt', 'creation_time': '2025-07-27T00:24:34.000000Z', 'com.apple.quicktime.make': 'Apple', 'com.apple.quicktime.model': 'Mac15,12', 'com.apple.quicktime.software': 'macOS 15.5 (24F74)', 'com.apple.quicktime.creationdate': '2025-07-27T09:21:08+0900'}, 'inputs': [{'streams': [{'input_number': 0, 'stream_number': 0, 'stream_type': 'video', 'language': None, 'default': True, 'size': [1280, 720], 'bitrate': 5564, 'fps': 59.95, 'codec_name': 'h264', 'profile': '(Main)', 'metadata': {'Metadata': '', 'creation_time': '2025-07-27T00:24:34.000000Z', 'handler_name': 'Core Media Video', 'vendor_id': '[0][0][0][0]', 'encoder': 'H.264'}}, {'input_number': 0, 'stream_number': 1, 'stream_type': 'audio', 'language': None, 'default': True, 'fps': 48000, 'bitrate': 255, 'metadata': {'Metadata': '', 'creation_time': '2025-07-27T00:24:34.000000Z', 'handler_name': 'Core Media Audio', 'vendor_id': '[0][0][0][0]'}}], 'input_number': 0}], 'duration': 64.94, 'bitrate': 5840, 'start': 0.0, 'default_video_input_number': 0, 'default_video_stream_number': 0, 'video_codec_name': 'h264', 'video_profile': '(Main)', 'video_size': [1280, 720], 'video_bitrate': 5564, 'video_fps': 59.95, 'default_audio_input_number': 0, 'default_audio_stream_number': 1, 'audio_fps': 48000, 'audio_bitrate': 255, 'video_duration': 64.94, 'video_n_frames': 3893}\n",
      "/opt/conda/lib/python3.10/site-packages/imageio_ffmpeg/binaries/ffmpeg-linux-x86_64-v7.0.2 -i /var/tmp/tmpuiqpnbr7/original/room_camera_example.mov -loglevel error -f image2pipe -vf scale=1280:720 -sws_flags bicubic -pix_fmt rgb24 -vcodec rawvideo -\n",
      "MoviePy - Building video /var/tmp/tmpuiqpnbr7/processed/room_camera_example.mp4.\n",
      "MoviePy - Writing audio in /var/tmp/tmpuiqpnbr7/temp-audio.mp3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n",
      "MoviePy - Writing video /var/tmp/tmpuiqpnbr7/processed/room_camera_example.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done !\n",
      "MoviePy - video ready /var/tmp/tmpuiqpnbr7/processed/room_camera_example.mp4\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'2025-01-01 00:00:00'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "original_video_path = 'original/room_camera_example.mov'\n",
    "processed_video_path = 'processed/room_camera_example.mp4'\n",
    "video_start_time = add_timestamp_overlay(\n",
    "    original_video_path,\n",
    "    processed_video_path,\n",
    ")\n",
    "\n",
    "video_start_time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f43f1b30-a439-4b16-9a3d-f051325cc6a5",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### 前処理実行後の動画を確認"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccd731f0-19fc-4626-8962-7ed5e08b8e30",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tmpfile = f'/tmp/tmp_movie_{uuid.uuid4()}.mp4'\n",
    "download_blob(processed_video_path, tmpfile)\n",
    "Video(tmpfile, embed=True, width=480)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "401cf554-28f5-4de8-a384-9edb75f597bb",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 動体検知処理"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96439e87-444a-46c8-8311-cc3c15fbe9c7",
   "metadata": {},
   "source": [
    "動画を 1 秒毎の区間に分けて、画面の 0.5% 以上の部分に移動物体が存在する区間を検知します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cd7dba77-3da5-44bb-960b-b92e2c163fd9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def detect_motion_events(video_path):\n",
    "    sampling_fps = 1\n",
    "    mog2_history = 500\n",
    "    mog2_var_threshold = 16\n",
    "    \n",
    "    with tempfile.TemporaryDirectory() as temp_dir:\n",
    "        video_source = os.path.join(temp_dir, video_path)\n",
    "        dirname, _ = os.path.split(video_source)\n",
    "        if dirname:\n",
    "            os.makedirs(dirname, exist_ok=True)\n",
    "        download_blob(video_path, video_source)\n",
    "        \n",
    "        cap = cv2.VideoCapture(video_source)\n",
    "\n",
    "        fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "        assert(sampling_fps <= fps)\n",
    "        frame_skip_interval = max(1, int(round(fps / sampling_fps)))\n",
    "        print(\n",
    "            f\"Video FPS: {fps}, Sampling FPS: {sampling_fps}, Frame Skip Interval: {frame_skip_interval}\"\n",
    "        )\n",
    "\n",
    "        # Initialize MOG2 background subtractor\n",
    "        fgbg_mog2 = cv2.createBackgroundSubtractorMOG2(\n",
    "            history=mog2_history, varThreshold=mog2_var_threshold, detectShadows=True\n",
    "        )\n",
    "\n",
    "        mog2_motion_timestamps = []\n",
    "        active_rate_list = []\n",
    "        frame_count = -1\n",
    "        kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (5, 5))\n",
    "        total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "\n",
    "        for _ in tqdm(\n",
    "            range(total_frames), desc=\"Processing video frames\", unit=\"frames\"\n",
    "        ):\n",
    "            frame_count += 1\n",
    "            ret, frame = cap.read()\n",
    "            if not ret:\n",
    "                break\n",
    "\n",
    "            # Process with sampling_fps\n",
    "            if frame_count % frame_skip_interval != 0:\n",
    "                continue\n",
    "\n",
    "            # Apply MOG2 to get foreground mask\n",
    "            fgmask_mog2 = fgbg_mog2.apply(frame)\n",
    "            fgmask_mog2 = cv2.morphologyEx(fgmask_mog2, cv2.MORPH_OPEN, kernel)\n",
    "            fgmask_mog2 = cv2.morphologyEx(fgmask_mog2, cv2.MORPH_CLOSE, kernel)\n",
    "\n",
    "            # Check if moving objects occupy more than 0.5% of the entire screen\n",
    "            mog2_motion_pixels = cv2.countNonZero(fgmask_mog2)\n",
    "            active_rate = (mog2_motion_pixels * 100) / (frame.shape[0] * frame.shape[1])\n",
    "            current_time = frame_count / fps\n",
    "\n",
    "            if active_rate > 0.5:\n",
    "                mog2_motion_timestamps.append(current_time)\n",
    "\n",
    "            if current_time == 0:\n",
    "                active_rate = 0\n",
    "            active_rate_list.append(active_rate)\n",
    "\n",
    "        cap.release()\n",
    "        video_duration = total_frames / fps if fps > 0 else 0.0\n",
    "\n",
    "    return {\n",
    "        \"video_duration\": video_duration,\n",
    "        \"event_timestamp\": mog2_motion_timestamps,\n",
    "        \"active_rate\": active_rate_list,\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b21f56c8-bde2-420c-a70d-60c768fce4e6",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 実行例"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31a81f10-9876-452d-9fa6-1b54ee7ba605",
   "metadata": {},
   "source": [
    "以下の情報が得られます。\n",
    "\n",
    "- `event_timestamp` : 0.5% 以上の部分に移動物体が存在する時刻（秒）\n",
    "- `active_rate`: 1 秒毎に画面上に移動物体が存在する領域の割合（%）を保存したリスト"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7e9e28a1-008a-4330-b617-cfe642bab1d7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video FPS: 59.95, Sampling FPS: 1, Frame Skip Interval: 60\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "599d2c12d8b44e44870959e8eb800cff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing video frames:   0%|          | 0/3893 [00:00<?, ?frames/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'video_duration': 64.93744787322768,\n",
       " 'event_timestamp': [0.0,\n",
       "  3.0025020850708923,\n",
       "  20.016680567139282,\n",
       "  21.017514595496245,\n",
       "  22.01834862385321,\n",
       "  23.019182652210173,\n",
       "  24.02001668056714,\n",
       "  25.0208507089241,\n",
       "  26.021684737281067,\n",
       "  27.02251876563803,\n",
       "  28.023352793994995,\n",
       "  29.024186822351957,\n",
       "  30.025020850708923,\n",
       "  31.025854879065886,\n",
       "  32.02668890742285,\n",
       "  33.027522935779814,\n",
       "  34.028356964136776,\n",
       "  35.029190992493746,\n",
       "  36.03002502085071,\n",
       "  37.03085904920767,\n",
       "  49.04086738949124,\n",
       "  50.0417014178482,\n",
       "  51.04253544620517,\n",
       "  52.043369474562134,\n",
       "  53.044203502919096,\n",
       "  54.04503753127606,\n",
       "  55.04587155963303,\n",
       "  56.04670558798999,\n",
       "  57.04753961634695],\n",
       " 'active_rate': [0,\n",
       "  0.025173611111111112,\n",
       "  0.0,\n",
       "  50.251302083333336,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.023871527777777776,\n",
       "  0.023871527777777776,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  3.08984375,\n",
       "  7.115885416666667,\n",
       "  11.36892361111111,\n",
       "  19.696180555555557,\n",
       "  17.9609375,\n",
       "  20.766493055555557,\n",
       "  17.565538194444443,\n",
       "  10.434027777777779,\n",
       "  13.216145833333334,\n",
       "  19.061197916666668,\n",
       "  22.018663194444443,\n",
       "  22.291666666666668,\n",
       "  4.571180555555555,\n",
       "  3.1766493055555554,\n",
       "  2.240451388888889,\n",
       "  2.6844618055555554,\n",
       "  2.4539930555555554,\n",
       "  1.6085069444444444,\n",
       "  0.3784722222222222,\n",
       "  0.3806423611111111,\n",
       "  0.4266493055555556,\n",
       "  0.4118923611111111,\n",
       "  0.3819444444444444,\n",
       "  0.3823784722222222,\n",
       "  0.3810763888888889,\n",
       "  0.2877604166666667,\n",
       "  0.21354166666666666,\n",
       "  0.059027777777777776,\n",
       "  0.3328993055555556,\n",
       "  3.3975694444444446,\n",
       "  25.385416666666668,\n",
       "  17.723524305555557,\n",
       "  15.707899305555555,\n",
       "  7.956597222222222,\n",
       "  12.51779513888889,\n",
       "  16.67621527777778,\n",
       "  20.87673611111111,\n",
       "  5.167100694444445,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.024305555555555556,\n",
       "  0.024305555555555556,\n",
       "  0.024305555555555556,\n",
       "  0.024305555555555556,\n",
       "  0.024305555555555556]}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "motion_events = detect_motion_events(processed_video_path)\n",
    "active_rate = motion_events['active_rate']\n",
    "motion_events"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b57971d-bc0f-4db1-87e2-eb361c6c87ed",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 動体検知結果から動画を区間に分割"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ba4e7f0-436c-4edc-a7c8-d107e759831f",
   "metadata": {},
   "source": [
    "以下のルールで、動画全体を no_event 区間と event 区間に分割します。\n",
    "\n",
    "- 動体が存在しない時間が `time_threshold`（秒）を超えて続く部分は no_event 区間として、それ以外は event 区間とします。\n",
    "- ただし、 event 区間の長さが `min_event_duration`（秒）以下の場合は、一時的なノイズと考えて、 no_event 区間とします。\n",
    "- event 区間が `max_event_duration`（秒）を超える場合は、Gemini API による分析精度が下がらないように、 `max_event_duration`（秒）ごとの連続する event 区間に分割します。ただし、最後の event 区間が 5 秒以下になる場合は、直前の event 区間にマージします。\n",
    "\n",
    "**例**\n",
    "\n",
    "- event_timestamp に含まれる時刻（秒）を 1、含まれない時刻（秒）を 0 で表した結果が次だとします。\n",
    "```\n",
    "[0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0]\n",
    "       ~~~~~~~                       ~~~~~~~~~~~~~\n",
    "```\n",
    "- `time_threshold = 1.5, min_event_duration=3.0` とした場合、上記の波線部分が event 区間になります。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "90f00581-c449-4231-9ac9-06d3111899f8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def analyze_motion_intervals(\n",
    "        mog2_motion_timestamps,\n",
    "        video_duration,\n",
    "        time_threshold=1.5,\n",
    "        min_event_duration=3.0,\n",
    "        max_event_duration=180.0,\n",
    "):\n",
    "    assert min_event_duration < max_event_duration\n",
    "\n",
    "    def add_event(event_list, start_time, end_time, event_type):\n",
    "        # The main logic should append event periods consecutively.\n",
    "        assert start_time <= end_time\n",
    "        if event_list:\n",
    "            assert event_list[-1]['end_time'] == start_time\n",
    "        else:\n",
    "            assert start_time == 0\n",
    "\n",
    "        # Ignore if start_time == end_time\n",
    "        if start_time == end_time:\n",
    "            return\n",
    "\n",
    "        # Join consecutive no_event periods\n",
    "        if (\n",
    "            event_type == 'no_event'\n",
    "            and event_list\n",
    "            and event_list[-1]['type'] == 'no_event'\n",
    "        ):\n",
    "            event_list[-1]['end_time'] = end_time\n",
    "            return\n",
    "\n",
    "        # Add an event period\n",
    "        event_list.append(\n",
    "            {'start_time': start_time, 'end_time': end_time, 'type': event_type}\n",
    "        )\n",
    "        return\n",
    "\n",
    "    event_intervals = []\n",
    "    timestamps = copy.copy(mog2_motion_timestamps)\n",
    "    current_start_time = current_end_time = 0\n",
    "\n",
    "    while timestamps:\n",
    "        event_timestamp = timestamps.pop(0)\n",
    "        if (\n",
    "            event_timestamp - current_end_time <= time_threshold\n",
    "        ):  # Event is continuing\n",
    "            current_end_time = event_timestamp\n",
    "            if (\n",
    "                timestamps\n",
    "                and current_end_time - current_start_time < max_event_duration\n",
    "            ):\n",
    "                continue\n",
    "\n",
    "        # Now split events as:\n",
    "        #   A. (current_start_time, current_end_time): event (or no_event if event_duration < min_event_duration)\n",
    "        #   B. (current_end_time, event_timestamp): no_event\n",
    "\n",
    "        # Add A.\n",
    "        event_duration = current_end_time - current_start_time\n",
    "        if (\n",
    "            event_intervals and event_intervals[-1]['type'] == 'event'\n",
    "        ):  # Event is continuing\n",
    "            if (\n",
    "                event_duration < 5\n",
    "            ):  # Extend the last event if the current event period is too short\n",
    "                event_intervals[-1]['end_time'] = current_end_time\n",
    "            else:\n",
    "                add_event(\n",
    "                    event_intervals, current_start_time, current_end_time, 'event'\n",
    "                )\n",
    "        elif event_duration >= min_event_duration:\n",
    "            add_event(\n",
    "                event_intervals, current_start_time, current_end_time, 'event'\n",
    "            )\n",
    "        else:\n",
    "            add_event(\n",
    "                event_intervals, current_start_time, current_end_time, 'no_event'\n",
    "            )\n",
    "\n",
    "        # Add B.\n",
    "        add_event(event_intervals, current_end_time, event_timestamp, 'no_event')\n",
    "\n",
    "        current_start_time = current_end_time = event_timestamp\n",
    "\n",
    "    # Add the final no_event (or maybe event) period until the end of the video.\n",
    "    if (event_intervals[-1]['type']=='event' and\n",
    "        video_duration - current_end_time <= time_threshold):\n",
    "        event_intervals[-1]['end_time'] = video_duration\n",
    "    else:\n",
    "        add_event(event_intervals, current_end_time, video_duration, 'no_event')            \n",
    "\n",
    "    return event_intervals"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7be025e9-68d7-4fb8-b445-8f44b025d6a7",
   "metadata": {},
   "source": [
    "#### 実行例"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f90e5466-8e77-4dbd-856b-929822a8a942",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'start_time': 0.0, 'end_time': 20.016680567139282, 'type': 'no_event'},\n",
       " {'start_time': 20.016680567139282,\n",
       "  'end_time': 37.03085904920767,\n",
       "  'type': 'event'},\n",
       " {'start_time': 37.03085904920767,\n",
       "  'end_time': 49.04086738949124,\n",
       "  'type': 'no_event'},\n",
       " {'start_time': 49.04086738949124,\n",
       "  'end_time': 57.04753961634695,\n",
       "  'type': 'event'},\n",
       " {'start_time': 57.04753961634695,\n",
       "  'end_time': 64.93744787322768,\n",
       "  'type': 'no_event'}]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_events = analyze_motion_intervals(\n",
    "    motion_events.get('event_timestamp'),\n",
    "    motion_events.get('video_duration'),\n",
    ")\n",
    "merged_events"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1f71ce2-4888-4676-94ba-b2be3623b9cb",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 動画の前処理から区間分割までをまとめて実行"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0081de76-53b5-4133-a296-d405e16a84d3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def detect_events(\n",
    "    video_path,\n",
    "    video_path_ts_overlay,\n",
    "    video_start_time='2025-01-01 00:00:00'\n",
    "):\n",
    "    print(f'# Preprocess: {video_path}')\n",
    "    add_timestamp_overlay(video_path, video_path_ts_overlay, video_start_time)\n",
    "    print(f'# Detect events: {video_path_ts_overlay}')\n",
    "    motion_events = detect_motion_events(video_path_ts_overlay)     \n",
    "    merged_events = analyze_motion_intervals(\n",
    "        motion_events.get('event_timestamp'),\n",
    "        motion_events.get(\"video_duration\"),\n",
    "    )\n",
    "    active_rate = motion_events.get('active_rate')\n",
    "\n",
    "    return {\n",
    "        'video_path_ts_overlay': video_path_ts_overlay,\n",
    "        'video_start_time': video_start_time,\n",
    "        'merged_events': merged_events,\n",
    "        'active_rate': active_rate,\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63a09ae0-cf06-4344-96d5-08b7d025414c",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 実行例"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c9014990-e53a-4fae-9e13-5ee12a469769",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Preprocess: original/room_camera_example.mov\n",
      "{'video_found': True, 'audio_found': True, 'metadata': {'major_brand': 'qt', 'minor_version': '0', 'compatible_brands': 'qt', 'creation_time': '2025-07-27T00:24:34.000000Z', 'com.apple.quicktime.make': 'Apple', 'com.apple.quicktime.model': 'Mac15,12', 'com.apple.quicktime.software': 'macOS 15.5 (24F74)', 'com.apple.quicktime.creationdate': '2025-07-27T09:21:08+0900'}, 'inputs': [{'streams': [{'input_number': 0, 'stream_number': 0, 'stream_type': 'video', 'language': None, 'default': True, 'size': [1280, 720], 'bitrate': 5564, 'fps': 59.95, 'codec_name': 'h264', 'profile': '(Main)', 'metadata': {'Metadata': '', 'creation_time': '2025-07-27T00:24:34.000000Z', 'handler_name': 'Core Media Video', 'vendor_id': '[0][0][0][0]', 'encoder': 'H.264'}}, {'input_number': 0, 'stream_number': 1, 'stream_type': 'audio', 'language': None, 'default': True, 'fps': 48000, 'bitrate': 255, 'metadata': {'Metadata': '', 'creation_time': '2025-07-27T00:24:34.000000Z', 'handler_name': 'Core Media Audio', 'vendor_id': '[0][0][0][0]'}}], 'input_number': 0}], 'duration': 64.94, 'bitrate': 5840, 'start': 0.0, 'default_video_input_number': 0, 'default_video_stream_number': 0, 'video_codec_name': 'h264', 'video_profile': '(Main)', 'video_size': [1280, 720], 'video_bitrate': 5564, 'video_fps': 59.95, 'default_audio_input_number': 0, 'default_audio_stream_number': 1, 'audio_fps': 48000, 'audio_bitrate': 255, 'video_duration': 64.94, 'video_n_frames': 3893}\n",
      "/opt/conda/lib/python3.10/site-packages/imageio_ffmpeg/binaries/ffmpeg-linux-x86_64-v7.0.2 -i /var/tmp/tmpg4n14l3v/original/room_camera_example.mov -loglevel error -f image2pipe -vf scale=1280:720 -sws_flags bicubic -pix_fmt rgb24 -vcodec rawvideo -\n",
      "MoviePy - Building video /var/tmp/tmpg4n14l3v/processed/room_camera_example.mp4.\n",
      "MoviePy - Writing audio in /var/tmp/tmpg4n14l3v/temp-audio.mp3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n",
      "MoviePy - Writing video /var/tmp/tmpg4n14l3v/processed/room_camera_example.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done !\n",
      "MoviePy - video ready /var/tmp/tmpg4n14l3v/processed/room_camera_example.mp4\n",
      "# Detect events: processed/room_camera_example.mp4\n",
      "Video FPS: 59.95, Sampling FPS: 1, Frame Skip Interval: 60\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9e19ce9915c04159bafd233610f48f38",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing video frames:   0%|          | 0/3893 [00:00<?, ?frames/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'video_path_ts_overlay': 'processed/room_camera_example.mp4',\n",
       " 'video_start_time': '2025-01-01 00:00:00',\n",
       " 'merged_events': [{'start_time': 0.0,\n",
       "   'end_time': 20.016680567139282,\n",
       "   'type': 'no_event'},\n",
       "  {'start_time': 20.016680567139282,\n",
       "   'end_time': 37.03085904920767,\n",
       "   'type': 'event'},\n",
       "  {'start_time': 37.03085904920767,\n",
       "   'end_time': 49.04086738949124,\n",
       "   'type': 'no_event'},\n",
       "  {'start_time': 49.04086738949124,\n",
       "   'end_time': 57.04753961634695,\n",
       "   'type': 'event'},\n",
       "  {'start_time': 57.04753961634695,\n",
       "   'end_time': 64.93744787322768,\n",
       "   'type': 'no_event'}],\n",
       " 'active_rate': [0,\n",
       "  0.025173611111111112,\n",
       "  0.0,\n",
       "  50.251302083333336,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.023871527777777776,\n",
       "  0.023871527777777776,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  3.08984375,\n",
       "  7.115885416666667,\n",
       "  11.36892361111111,\n",
       "  19.696180555555557,\n",
       "  17.9609375,\n",
       "  20.766493055555557,\n",
       "  17.565538194444443,\n",
       "  10.434027777777779,\n",
       "  13.216145833333334,\n",
       "  19.061197916666668,\n",
       "  22.018663194444443,\n",
       "  22.291666666666668,\n",
       "  4.571180555555555,\n",
       "  3.1766493055555554,\n",
       "  2.240451388888889,\n",
       "  2.6844618055555554,\n",
       "  2.4539930555555554,\n",
       "  1.6085069444444444,\n",
       "  0.3784722222222222,\n",
       "  0.3806423611111111,\n",
       "  0.4266493055555556,\n",
       "  0.4118923611111111,\n",
       "  0.3819444444444444,\n",
       "  0.3823784722222222,\n",
       "  0.3810763888888889,\n",
       "  0.2877604166666667,\n",
       "  0.21354166666666666,\n",
       "  0.059027777777777776,\n",
       "  0.3328993055555556,\n",
       "  3.3975694444444446,\n",
       "  25.385416666666668,\n",
       "  17.723524305555557,\n",
       "  15.707899305555555,\n",
       "  7.956597222222222,\n",
       "  12.51779513888889,\n",
       "  16.67621527777778,\n",
       "  20.87673611111111,\n",
       "  5.167100694444445,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.024305555555555556,\n",
       "  0.024305555555555556,\n",
       "  0.024305555555555556,\n",
       "  0.024305555555555556,\n",
       "  0.024305555555555556]}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = detect_events(\n",
    "    original_video_path,\n",
    "    processed_video_path,\n",
    ")\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fb3284c4-5490-4464-ab35-6f4b94cd6fb8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "video_path = result.get('video_path_ts_overlay')\n",
    "video_start_time = result.get('video_start_time')\n",
    "merged_events = result.get('merged_events')\n",
    "active_rate = result.get('active_rate')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08f62317-329f-43c6-8bef-8bc9ffa98c2f",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 各区間を Gemini API で分析"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3143f62f-c33c-4e55-b4c3-b24dfea22132",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 事前準備"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ec98a0d-d022-4ce5-b73a-94d3f352e460",
   "metadata": {},
   "source": [
    "分析処理を構成する個別の処理を関数として用意します。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04763976-42b8-45df-b2d4-0df5595677f5",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### 出力スキーマの定義"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0101bf9f-6e1e-4283-9a5b-a2e718ebefca",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_event_schema():\n",
    "    \"\"\"Get the schema for event analysis\"\"\"\n",
    "    return {\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\n",
    "            \"real_start_time\": {\n",
    "                \"description\": \"start time in YYYY-MM-DD HH:MM:SS format\",\n",
    "                \"type\": \"string\"\n",
    "            },\n",
    "            \"real_end_time\": {\n",
    "                \"description\": \"end time in YYYY-MM-DD HH:MM:SS format\",\n",
    "                \"type\": \"string\"\n",
    "            },\n",
    "            \"status\": {\n",
    "                \"description\": \"Status of the scene\",\n",
    "                \"enum\": [\"usual\", \"unusual\"],\n",
    "                \"type\": \"string\"\n",
    "            },\n",
    "            \"summary\": {\n",
    "                \"description\": \"One sentence summary of the scene\",\n",
    "                \"type\": \"string\"\n",
    "            },\n",
    "            \"details\": {\n",
    "                \"description\": \"Detailed description of the scene\",\n",
    "                \"type\": \"string\"\n",
    "            }\n",
    "        },\n",
    "        \"required\": [\"real_start_time\", \"real_end_time\", \"status\", \"summary\", \"details\"]\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ca0224f-be28-45c3-a558-75b89ad232b8",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### \"no_event\" 区間の分析"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c4b75d45-07f0-4f47-9ade-0fc5a8ac4ccf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def extract_snapshot(video_path, time_sec, output_path):\n",
    "    \"\"\"Extract a snapshot from video at specific time\"\"\"\n",
    "    with VideoFileClip(video_path) as clip:\n",
    "        clip.save_frame(output_path, t=int(time_sec))\n",
    "            \n",
    "\n",
    "def process_no_event_duration(video_path, start_time, end_time, language=\"English\"):\n",
    "    \"\"\"Process a no_event duration by analyzing snapshots at start and end\"\"\"\n",
    "    duration = end_time - start_time\n",
    "        \n",
    "    system_instruction = f\"\"\"\n",
    "You are given two images from a security camera:\n",
    "- The first image is at the start of the period.\n",
    "- The second image is at the end of the same period. \n",
    "- There's no outstanding events during the period.\n",
    "- Timestamp is on the top-left side or bottom-left side of the movie in the format \"YYYY-MM-DD HH:MM:SS\".\n",
    "- Please be aware that the location and format of the timestamp may change depending on the video.\n",
    "- The time duration of the period is {duration} seconds.\n",
    "\n",
    "[tasks]\n",
    "- Analyze both images and give the following information:\n",
    "  * \"real_start_time\": start time of the scene in the format \"YYYY-MM-DD HH:MM:SS\" (extract the full timestamp from the image).\n",
    "  * \"real_end_time\": end time of the scene in the format \"YYYY-MM-DD HH:MM:SS\" (extract the full timestamp from the image).\n",
    "  * \"status\": One of the following item \"usual\" or \"unusual\".\n",
    "  * \"summary\": A short summary of the overall state of the scene during this period based on these two snapshots.\n",
    "  * \"details\": Detailed description of the scene with a few sentences.\n",
    "- \"summary\" is a noun form sentence with around 10 words.\n",
    "\n",
    "[output]\n",
    "- Output in {language}.\n",
    "- Return the result as a JSON list.\n",
    "\"\"\"\n",
    "        \n",
    "    response_schema = get_event_schema()\n",
    "        \n",
    "    with tempfile.TemporaryDirectory() as tmpdir:\n",
    "        tmpfile_start = os.path.join(tmpdir, 'start.png')\n",
    "        tmpfile_end = os.path.join(tmpdir, 'end.png')\n",
    "            \n",
    "        extract_snapshot(video_path, start_time, tmpfile_start)\n",
    "        extract_snapshot(video_path, end_time, tmpfile_end)\n",
    "            \n",
    "        parts = [Part.from_text(text='[images]')]\n",
    "            \n",
    "        with open(tmpfile_start, 'rb') as f:\n",
    "            img_bytes = f.read()\n",
    "            parts.append(Part.from_bytes(data=img_bytes, mime_type='image/png'))\n",
    "            \n",
    "        with open(tmpfile_end, 'rb') as f:\n",
    "            img_bytes = f.read()\n",
    "            parts.append(Part.from_bytes(data=img_bytes, mime_type='image/png'))\n",
    "            \n",
    "        result = analyze_content(\n",
    "            system_instruction=system_instruction,\n",
    "            contents=Content(parts=parts, role='user'),\n",
    "            response_schema=response_schema,\n",
    "        )\n",
    "            \n",
    "        return result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be780979-75e4-40c0-b1ab-de0b7eb1efba",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### \"event\" 区間の分析"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cbb158a4-397b-47e2-a9ad-e14a9a801fdd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def extract_video_clip(\n",
    "    video_path,\n",
    "    start_time,\n",
    "    end_time,\n",
    "    output_path,\n",
    "    fps=20,\n",
    "    resize_factor=1.0,\n",
    "):\n",
    "    \"\"\"Extract a video clip from start_time to end_time\"\"\"\n",
    "    with VideoFileClip(video_path) as clip:\n",
    "        sub_clip = clip.subclipped(start_time, end_time)\n",
    "\n",
    "        # When audio is not available, moviepy raises an error\n",
    "        # when trying to write an audio file.\n",
    "        if sub_clip.audio is None:\n",
    "            sub_clip.write_videofile(\n",
    "                output_path,\n",
    "                fps=fps,\n",
    "                audio=False,\n",
    "                logger=None\n",
    "            )\n",
    "        else:\n",
    "            temp_dir, _ = os.path.split(output_path)\n",
    "            sub_clip.write_videofile(\n",
    "                output_path,\n",
    "                fps=fps,\n",
    "                audio_codec='libmp3lame',\n",
    "                # temp_audiofile should be in temp_dir\n",
    "                temp_audiofile=os.path.join(temp_dir, 'temp-audio.mp3'),\n",
    "                remove_temp=True,\n",
    "                logger=None\n",
    "            )\n",
    "\n",
    "            \n",
    "def process_event_duration(video_path, start_time, end_time, language=\"English\"):\n",
    "    \"\"\"Process an event duration by analyzing the video clip\"\"\"\n",
    "    system_instruction = f\"\"\"\n",
    "You are given a video clip from a security camera:\n",
    "- The video clip contains moving objects in almost all time period. Focus on the moving objects in each scene.\n",
    "- Timestamp is on the top-left side or bottom-left side of the movie in the format \"YYYY-MM-DD HH:MM:SS\".\n",
    "- Please be aware that the location and format of the timestamp may change depending on the video.\n",
    "\n",
    "[tasks]\n",
    "- Analyze the video clip and split them into independent scenes, and give the following information to each scene.\n",
    "  * \"real_start_time\": start time of the scene in the format \"YYYY-MM-DD HH:MM:SS\" (extract the full timestamp from the video).\n",
    "  * \"real_end_time\": end time of the scene in the format \"YYYY-MM-DD HH:MM:SS\" (extract the full timestamp from the video).\n",
    "  * \"status\": One of the following item \"usual\" or \"unusual\".\n",
    "  * \"summary\": A short summary of the overall state of the scene during this period based on these two snapshots.\n",
    "  * \"details\": Detailed description of the scene with a few sentences.\n",
    "- \"summary\" is a noun form sentence with around 15 words.\n",
    "\n",
    "[output]\n",
    "- Output in {language}.\n",
    "- Return the result as a JSON list.\n",
    "\"\"\"\n",
    "\n",
    "    response_schema = {\n",
    "        \"type\": \"array\",\n",
    "        \"items\": get_event_schema()\n",
    "    }\n",
    "        \n",
    "    with tempfile.TemporaryDirectory() as tmpdir:\n",
    "        clip_file = os.path.join(tmpdir, 'video_clip.mp4')\n",
    "        \n",
    "        extract_video_clip(\n",
    "            video_path, start_time, end_time, clip_file\n",
    "        )\n",
    "        parts = [Part.from_text(text='[video clip]')]\n",
    "            \n",
    "        with open(clip_file, 'rb') as f:\n",
    "            video_bytes = f.read()\n",
    "            parts.append(Part.from_bytes(data=video_bytes, mime_type='video/mp4'))\n",
    "            \n",
    "        result = analyze_content(\n",
    "            system_instruction=system_instruction,\n",
    "            contents=Content(parts=parts, role='user'),\n",
    "            response_schema=response_schema,\n",
    "        )     \n",
    "        \n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "570729bd-cf40-4e25-ab3f-f29fcc4589e5",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### 複数の区間をスレッドで並列処理するためのクラス"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "05313a46-77fb-4336-b910-acb66f1e462a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class EventProcessThread(threading.Thread):\n",
    "    \"\"\"Thread for processing events in parallel\"\"\"\n",
    "    \n",
    "    def __init__(self, name, video_path, video_start_time, events, language):\n",
    "        super().__init__()\n",
    "        self.name = name\n",
    "        self.video_path = video_path\n",
    "        self.video_start_time = video_start_time\n",
    "        self.events = events\n",
    "        self.language = language\n",
    "        self.result = []\n",
    "\n",
    "    def run(self):\n",
    "        while self.events:\n",
    "            event = self.events.pop(0)\n",
    "            self.process_event(event)\n",
    "\n",
    "    def to_unix_time(self, datetime_string):\n",
    "        unix_time = datetime.strptime(\n",
    "            datetime_string, '%Y-%m-%d %H:%M:%S'\n",
    "        ).timestamp()\n",
    "        return unix_time\n",
    "\n",
    "    def from_unix_time(self, unix_time):\n",
    "        dt_object = datetime.fromtimestamp(unix_time)\n",
    "        formatted_string = dt_object.strftime('%Y-%m-%d %H:%M:%S')\n",
    "        return formatted_string\n",
    "    \n",
    "    def process_event(self, event):\n",
    "        start_time, end_time = event['start_time'], event['end_time']\n",
    "        event_type = event['type']\n",
    "        print(f'Thread [{self.name}] - Processing: {start_time}-{end_time} ({event_type})')\n",
    "\n",
    "        if event_type == 'no_event':\n",
    "            event_data = process_no_event_duration(\n",
    "                self.video_path, start_time, end_time, self.language\n",
    "            )\n",
    "            if event_data:\n",
    "                # Adjust detected timestamp\n",
    "                basetime = self.to_unix_time(self.video_start_time)\n",
    "                start_time, end_time = int(event['start_time']), int(event['end_time'])\n",
    "                if self.to_unix_time(event_data['real_start_time']) != basetime + start_time:\n",
    "                    print(f\"Thread [{self.name}] - Adjust real_start_time from {event_data['real_start_time']} to {self.from_unix_time(basetime + start_time)}\")\n",
    "                    event_data['real_start_time'] = self.from_unix_time(basetime + start_time)\n",
    "                if self.to_unix_time(event_data['real_end_time']) != basetime + end_time:\n",
    "                    print(f\"Thread [{self.name}] - Adjust real_end_time from {event_data['real_end_time']} to {self.from_unix_time(basetime + end_time)}\")\n",
    "                    event_data['real_end_time'] = self.from_unix_time(basetime + end_time)\n",
    "\n",
    "                event_data['scene_type'] = 'no_event'\n",
    "                event_data['start_time'] = start_time\n",
    "                event_data['end_time'] = end_time\n",
    "                self.result.append(event_data)\n",
    "\n",
    "        elif event_type == 'event':\n",
    "            event_data_list = process_event_duration(\n",
    "                self.video_path, start_time, end_time, self.language\n",
    "            )\n",
    "            if event_data_list:\n",
    "                event_data_list = sorted(event_data_list, key=lambda event: event['real_start_time'])\n",
    "\n",
    "                # Adjust detected timestamp\n",
    "                result = []\n",
    "                basetime = self.to_unix_time(self.video_start_time)\n",
    "                start_time, end_time = int(event['start_time']), int(event['end_time'])\n",
    "                current_start_time = start_time\n",
    "                for event_data in event_data_list:\n",
    "                    event_data['start_time'] = int(current_start_time)\n",
    "\n",
    "                    if self.to_unix_time(event_data['real_start_time']) != basetime + current_start_time:\n",
    "                        print(f\"Thread [{self.name}] - Adjust real_start_time from {event_data['real_start_time']} to {self.from_unix_time(basetime + current_start_time)}\")\n",
    "                        event_data['real_start_time'] = self.from_unix_time(basetime + current_start_time)\n",
    "                    current_start_time = self.to_unix_time(event_data['real_end_time']) - basetime\n",
    "\n",
    "                    event_data['scene_type'] = 'event'\n",
    "                    event_data['end_time'] = int(current_start_time)\n",
    "\n",
    "                    result.append(event_data)\n",
    "\n",
    "                if self.to_unix_time(result[-1]['real_end_time']) != basetime + end_time:\n",
    "                    print(f\"Thread [{self.name}] - Adjust real_end_time from {result[-1]['real_end_time']} to {self.from_unix_time(basetime + end_time)}\")\n",
    "                    result[-1]['real_end_time'] = self.from_unix_time(basetime + end_time)\n",
    "                    result[-1]['end_time'] = end_time\n",
    "                    \n",
    "                self.result += result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b601c8b8-e41f-462a-8968-6f682bcb78dc",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### 動画サマリーの生成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a0f15bdd-8a91-4f30-b18a-3bf6988147a5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def generate_summary(event_list, language=\"English\"):\n",
    "    \"\"\"Generate a summary of all events\"\"\"\n",
    "    system_instruction = f\"\"\"\n",
    "You are given a timeseries data describing contents of a security camera recording.\n",
    "\n",
    "[tasks]\n",
    "- Give a short summary of the contents.\n",
    "- The summary is a noun form sentence with around 10 words.\n",
    "\n",
    "[output]\n",
    "- Output in {language}.\n",
    "- return the result as a single JSON object.\n",
    "\"\"\"\n",
    "\n",
    "    response_schema = {\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\n",
    "            \"summary\": {\n",
    "                \"description\": \"One sentence summary of the contents\",\n",
    "                \"type\": \"string\"\n",
    "            },\n",
    "        },\n",
    "        \"required\": [\"summary\"]\n",
    "    }\n",
    "        \n",
    "    parts = [Part.from_text(text=json.dumps(event_list))]\n",
    "        \n",
    "    result = analyze_content(\n",
    "        system_instruction=system_instruction,\n",
    "        contents=Content(parts=parts, role='user'),\n",
    "        response_schema=response_schema,\n",
    "    )\n",
    "        \n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fc72cf0-e028-49a0-9378-9a905603e221",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 分析を実行"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe38183b-99ac-491a-8b49-f738cc0dc209",
   "metadata": {},
   "source": [
    "用意した関数を用いて、動画の各区間を分析します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "28899676-4182-4fd6-8ca5-e1ab682ad209",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def analyze_events(\n",
    "    processed_video_path,\n",
    "    video_start_time,\n",
    "    merged_events,\n",
    "    language=\"English\",\n",
    "    num_parallel=4\n",
    "):\n",
    "    with tempfile.TemporaryDirectory() as temp_dir:\n",
    "        video_path = os.path.join(temp_dir, processed_video_path)\n",
    "        dirname, _ = os.path.split(video_path)\n",
    "        if dirname:\n",
    "            os.makedirs(dirname, exist_ok=True)\n",
    "        download_blob(processed_video_path, video_path)\n",
    "\n",
    "        # Create threads for parallel processing\n",
    "        threads = []\n",
    "        events_copy = merged_events.copy()  # Make a copy to avoid modifying original\n",
    "        \n",
    "        for i in range(num_parallel):\n",
    "            thread = EventProcessThread(\n",
    "                name=f'{i+1:02d}',\n",
    "                video_path=video_path,\n",
    "                video_start_time=video_start_time,\n",
    "                events=events_copy,\n",
    "                language=language,\n",
    "            )\n",
    "            threads.append(thread)\n",
    "            thread.start()\n",
    "        \n",
    "        # Wait for all threads to complete\n",
    "        result = []\n",
    "        for thread in threads:\n",
    "            thread.join()\n",
    "            if thread.result:\n",
    "                result += thread.result\n",
    "        \n",
    "        # Sort results by start time\n",
    "        result = sorted(result, key=lambda event: event['start_time'])\n",
    "        \n",
    "        # Generate summary\n",
    "        print('Generating a summary text.')\n",
    "        summary_data = generate_summary(result, language)\n",
    "        \n",
    "        return {\n",
    "            'summary': summary_data.get('summary', ''),\n",
    "            'events': result,\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2956b78-f46e-44b8-b660-8db8b693b2c7",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### 実行例"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0bb0e031-6aa0-4615-802d-f0e033d8d479",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thread [01] - Processing: 0.0-20.016680567139282 (no_event)\n",
      "Thread [02] - Processing: 20.016680567139282-37.03085904920767 (event)\n",
      "Thread [03] - Processing: 37.03085904920767-49.04086738949124 (no_event)\n",
      "Thread [04] - Processing: 49.04086738949124-57.04753961634695 (event)\n",
      "Thread [05] - Processing: 57.04753961634695-64.93744787322768 (no_event)\n",
      "{'video_found': True, 'audio_found': True, 'metadata': {'major_brand': 'isom', 'minor_version': '512', 'compatible_brands': 'isomiso2avc1mp41', 'encoder': 'Lavf61.1.100'}, 'inputs': [{'streams': [{'input_number': 0, 'stream_number': 0, 'stream_type': 'video', 'language': None, 'default': True, 'size': [640, 360], 'bitrate': 97, 'fps': 59.95, 'codec_name': 'h264', 'profile': '(High)', 'metadata': {'Metadata': '', 'handler_name': 'VideoHandler', 'vendor_id': '[0][0][0][0]', 'encoder': 'Lavc61.3.100 libx264'}}, {'input_number': 0, 'stream_number': 1, 'stream_type': 'audio', 'language': None, 'default': True, 'fps': 44100, 'bitrate': 127, 'metadata': {'Metadata': '', 'handler_name': 'SoundHandler', 'vendor_id': '[0][0][0][0]'}}], 'input_number': 0}], 'duration': 64.94, 'bitrate': 238, 'start': 0.0, 'default_video_input_number': 0, 'default_video_stream_number': 0, 'video_codec_name': 'h264', 'video_profile': '(High)', 'video_size': [640, 360], 'video_bitrate': 97, 'video_fps': 59.95, 'default_audio_input_number': 0, 'default_audio_stream_number': 1, 'audio_fps': 44100, 'audio_bitrate': 127, 'video_duration': 64.94, 'video_n_frames': 3893}\n",
      "/opt/conda/lib/python3.10/site-packages/imageio_ffmpeg/binaries/ffmpeg-linux-x86_64-v7.0.2 -i /var/tmp/tmpizxd0ub0/processed/room_camera_example.mp4 -loglevel error -f image2pipe -vf scale=640:360 -sws_flags bicubic -pix_fmt rgb24 -vcodec rawvideo -\n",
      "{'video_found': True, 'audio_found': True, 'metadata': {'major_brand': 'isom', 'minor_version': '512', 'compatible_brands': 'isomiso2avc1mp41', 'encoder': 'Lavf61.1.100'}, 'inputs': [{'streams': [{'input_number': 0, 'stream_number': 0, 'stream_type': 'video', 'language': None, 'default': True, 'size': [640, 360], 'bitrate': 97, 'fps': 59.95, 'codec_name': 'h264', 'profile': '(High)', 'metadata': {'Metadata': '', 'handler_name': 'VideoHandler', 'vendor_id': '[0][0][0][0]', 'encoder': 'Lavc61.3.100 libx264'}}, {'input_number': 0, 'stream_number': 1, 'stream_type': 'audio', 'language': None, 'default': True, 'fps': 44100, 'bitrate': 127, 'metadata': {'Metadata': '', 'handler_name': 'SoundHandler', 'vendor_id': '[0][0][0][0]'}}], 'input_number': 0}], 'duration': 64.94, 'bitrate': 238, 'start': 0.0, 'default_video_input_number': 0, 'default_video_stream_number': 0, 'video_codec_name': 'h264', 'video_profile': '(High)', 'video_size': [640, 360], 'video_bitrate': 97, 'video_fps': 59.95, 'default_audio_input_number': 0, 'default_audio_stream_number': 1, 'audio_fps': 44100, 'audio_bitrate': 127, 'video_duration': 64.94, 'video_n_frames': 3893}\n",
      "/opt/conda/lib/python3.10/site-packages/imageio_ffmpeg/binaries/ffmpeg-linux-x86_64-v7.0.2 -i /var/tmp/tmpizxd0ub0/processed/room_camera_example.mp4 -loglevel error -f image2pipe -vf scale=640:360 -sws_flags bicubic -pix_fmt rgb24 -vcodec rawvideo -\n",
      "{'video_found': True, 'audio_found': True, 'metadata': {'major_brand': 'isom', 'minor_version': '512', 'compatible_brands': 'isomiso2avc1mp41', 'encoder': 'Lavf61.1.100'}, 'inputs': [{'streams': [{'input_number': 0, 'stream_number': 0, 'stream_type': 'video', 'language': None, 'default': True, 'size': [640, 360], 'bitrate': 97, 'fps': 59.95, 'codec_name': 'h264', 'profile': '(High)', 'metadata': {'Metadata': '', 'handler_name': 'VideoHandler', 'vendor_id': '[0][0][0][0]', 'encoder': 'Lavc61.3.100 libx264'}}, {'input_number': 0, 'stream_number': 1, 'stream_type': 'audio', 'language': None, 'default': True, 'fps': 44100, 'bitrate': 127, 'metadata': {'Metadata': '', 'handler_name': 'SoundHandler', 'vendor_id': '[0][0][0][0]'}}], 'input_number': 0}], 'duration': 64.94, 'bitrate': 238, 'start': 0.0, 'default_video_input_number': 0, 'default_video_stream_number': 0, 'video_codec_name': 'h264', 'video_profile': '(High)', 'video_size': [640, 360], 'video_bitrate': 97, 'video_fps': 59.95, 'default_audio_input_number': 0, 'default_audio_stream_number': 1, 'audio_fps': 44100, 'audio_bitrate': 127, 'video_duration': 64.94, 'video_n_frames': 3893}\n",
      "/opt/conda/lib/python3.10/site-packages/imageio_ffmpeg/binaries/ffmpeg-linux-x86_64-v7.0.2 -i /var/tmp/tmpizxd0ub0/processed/room_camera_example.mp4 -loglevel error -f image2pipe -vf scale=640:360 -sws_flags bicubic -pix_fmt rgb24 -vcodec rawvideo -\n",
      "{'video_found': True, 'audio_found': True, 'metadata': {'major_brand': 'isom', 'minor_version': '512', 'compatible_brands': 'isomiso2avc1mp41', 'encoder': 'Lavf61.1.100'}, 'inputs': [{'streams': [{'input_number': 0, 'stream_number': 0, 'stream_type': 'video', 'language': None, 'default': True, 'size': [640, 360], 'bitrate': 97, 'fps': 59.95, 'codec_name': 'h264', 'profile': '(High)', 'metadata': {'Metadata': '', 'handler_name': 'VideoHandler', 'vendor_id': '[0][0][0][0]', 'encoder': 'Lavc61.3.100 libx264'}}, {'input_number': 0, 'stream_number': 1, 'stream_type': 'audio', 'language': None, 'default': True, 'fps': 44100, 'bitrate': 127, 'metadata': {'Metadata': '', 'handler_name': 'SoundHandler', 'vendor_id': '[0][0][0][0]'}}], 'input_number': 0}], 'duration': 64.94, 'bitrate': 238, 'start': 0.0, 'default_video_input_number': 0, 'default_video_stream_number': 0, 'video_codec_name': 'h264', 'video_profile': '(High)', 'video_size': [640, 360], 'video_bitrate': 97, 'video_fps': 59.95, 'default_audio_input_number': 0, 'default_audio_stream_number': 1, 'audio_fps': 44100, 'audio_bitrate': 127, 'video_duration': 64.94, 'video_n_frames': 3893}\n",
      "/opt/conda/lib/python3.10/site-packages/imageio_ffmpeg/binaries/ffmpeg-linux-x86_64-v7.0.2 -i /var/tmp/tmpizxd0ub0/processed/room_camera_example.mp4 -loglevel error -f image2pipe -vf scale=640:360 -sws_flags bicubic -pix_fmt rgb24 -vcodec rawvideo -\n",
      "{'video_found': True, 'audio_found': True, 'metadata': {'major_brand': 'isom', 'minor_version': '512', 'compatible_brands': 'isomiso2avc1mp41', 'encoder': 'Lavf61.1.100'}, 'inputs': [{'streams': [{'input_number': 0, 'stream_number': 0, 'stream_type': 'video', 'language': None, 'default': True, 'size': [640, 360], 'bitrate': 97, 'fps': 59.95, 'codec_name': 'h264', 'profile': '(High)', 'metadata': {'Metadata': '', 'handler_name': 'VideoHandler', 'vendor_id': '[0][0][0][0]', 'encoder': 'Lavc61.3.100 libx264'}}, {'input_number': 0, 'stream_number': 1, 'stream_type': 'audio', 'language': None, 'default': True, 'fps': 44100, 'bitrate': 127, 'metadata': {'Metadata': '', 'handler_name': 'SoundHandler', 'vendor_id': '[0][0][0][0]'}}], 'input_number': 0}], 'duration': 64.94, 'bitrate': 238, 'start': 0.0, 'default_video_input_number': 0, 'default_video_stream_number': 0, 'video_codec_name': 'h264', 'video_profile': '(High)', 'video_size': [640, 360], 'video_bitrate': 97, 'video_fps': 59.95, 'default_audio_input_number': 0, 'default_audio_stream_number': 1, 'audio_fps': 44100, 'audio_bitrate': 127, 'video_duration': 64.94, 'video_n_frames': 3893}\n",
      "/opt/conda/lib/python3.10/site-packages/imageio_ffmpeg/binaries/ffmpeg-linux-x86_64-v7.0.2 -i /var/tmp/tmpizxd0ub0/processed/room_camera_example.mp4 -loglevel error -f image2pipe -vf scale=640:360 -sws_flags bicubic -pix_fmt rgb24 -vcodec rawvideo -\n",
      "{'video_found': True, 'audio_found': True, 'metadata': {'major_brand': 'isom', 'minor_version': '512', 'compatible_brands': 'isomiso2avc1mp41', 'encoder': 'Lavf61.1.100'}, 'inputs': [{'streams': [{'input_number': 0, 'stream_number': 0, 'stream_type': 'video', 'language': None, 'default': True, 'size': [640, 360], 'bitrate': 97, 'fps': 59.95, 'codec_name': 'h264', 'profile': '(High)', 'metadata': {'Metadata': '', 'handler_name': 'VideoHandler', 'vendor_id': '[0][0][0][0]', 'encoder': 'Lavc61.3.100 libx264'}}, {'input_number': 0, 'stream_number': 1, 'stream_type': 'audio', 'language': None, 'default': True, 'fps': 44100, 'bitrate': 127, 'metadata': {'Metadata': '', 'handler_name': 'SoundHandler', 'vendor_id': '[0][0][0][0]'}}], 'input_number': 0}], 'duration': 64.94, 'bitrate': 238, 'start': 0.0, 'default_video_input_number': 0, 'default_video_stream_number': 0, 'video_codec_name': 'h264', 'video_profile': '(High)', 'video_size': [640, 360], 'video_bitrate': 97, 'video_fps': 59.95, 'default_audio_input_number': 0, 'default_audio_stream_number': 1, 'audio_fps': 44100, 'audio_bitrate': 127, 'video_duration': 64.94, 'video_n_frames': 3893}\n",
      "/opt/conda/lib/python3.10/site-packages/imageio_ffmpeg/binaries/ffmpeg-linux-x86_64-v7.0.2 -ss 36.000000 -i /var/tmp/tmpizxd0ub0/processed/room_camera_example.mp4 -ss 1.000000 -loglevel error -f image2pipe -vf scale=640:360 -sws_flags bicubic -pix_fmt rgb24 -vcodec rawvideo -\n",
      "{'video_found': True, 'audio_found': True, 'metadata': {'major_brand': 'isom', 'minor_version': '512', 'compatible_brands': 'isomiso2avc1mp41', 'encoder': 'Lavf61.1.100'}, 'inputs': [{'streams': [{'input_number': 0, 'stream_number': 0, 'stream_type': 'video', 'language': None, 'default': True, 'size': [640, 360], 'bitrate': 97, 'fps': 59.95, 'codec_name': 'h264', 'profile': '(High)', 'metadata': {'Metadata': '', 'handler_name': 'VideoHandler', 'vendor_id': '[0][0][0][0]', 'encoder': 'Lavc61.3.100 libx264'}}, {'input_number': 0, 'stream_number': 1, 'stream_type': 'audio', 'language': None, 'default': True, 'fps': 44100, 'bitrate': 127, 'metadata': {'Metadata': '', 'handler_name': 'SoundHandler', 'vendor_id': '[0][0][0][0]'}}], 'input_number': 0}], 'duration': 64.94, 'bitrate': 238, 'start': 0.0, 'default_video_input_number': 0, 'default_video_stream_number': 0, 'video_codec_name': 'h264', 'video_profile': '(High)', 'video_size': [640, 360], 'video_bitrate': 97, 'video_fps': 59.95, 'default_audio_input_number': 0, 'default_audio_stream_number': 1, 'audio_fps': 44100, 'audio_bitrate': 127, 'video_duration': 64.94, 'video_n_frames': 3893}\n",
      "/opt/conda/lib/python3.10/site-packages/imageio_ffmpeg/binaries/ffmpeg-linux-x86_64-v7.0.2 -ss 19.016681 -i /var/tmp/tmpizxd0ub0/processed/room_camera_example.mp4 -ss 1.000000 -loglevel error -f image2pipe -vf scale=640:360 -sws_flags bicubic -pix_fmt rgb24 -vcodec rawvideo -\n",
      "{'video_found': True, 'audio_found': True, 'metadata': {'major_brand': 'isom', 'minor_version': '512', 'compatible_brands': 'isomiso2avc1mp41', 'encoder': 'Lavf61.1.100'}, 'inputs': [{'streams': [{'input_number': 0, 'stream_number': 0, 'stream_type': 'video', 'language': None, 'default': True, 'size': [640, 360], 'bitrate': 97, 'fps': 59.95, 'codec_name': 'h264', 'profile': '(High)', 'metadata': {'Metadata': '', 'handler_name': 'VideoHandler', 'vendor_id': '[0][0][0][0]', 'encoder': 'Lavc61.3.100 libx264'}}, {'input_number': 0, 'stream_number': 1, 'stream_type': 'audio', 'language': None, 'default': True, 'fps': 44100, 'bitrate': 127, 'metadata': {'Metadata': '', 'handler_name': 'SoundHandler', 'vendor_id': '[0][0][0][0]'}}], 'input_number': 0}], 'duration': 64.94, 'bitrate': 238, 'start': 0.0, 'default_video_input_number': 0, 'default_video_stream_number': 0, 'video_codec_name': 'h264', 'video_profile': '(High)', 'video_size': [640, 360], 'video_bitrate': 97, 'video_fps': 59.95, 'default_audio_input_number': 0, 'default_audio_stream_number': 1, 'audio_fps': 44100, 'audio_bitrate': 127, 'video_duration': 64.94, 'video_n_frames': 3893}\n",
      "/opt/conda/lib/python3.10/site-packages/imageio_ffmpeg/binaries/ffmpeg-linux-x86_64-v7.0.2 -ss 56.000000 -i /var/tmp/tmpizxd0ub0/processed/room_camera_example.mp4 -ss 1.000000 -loglevel error -f image2pipe -vf scale=640:360 -sws_flags bicubic -pix_fmt rgb24 -vcodec rawvideo -\n",
      "{'video_found': True, 'audio_found': True, 'metadata': {'major_brand': 'isom', 'minor_version': '512', 'compatible_brands': 'isomiso2avc1mp41', 'encoder': 'Lavf61.1.100'}, 'inputs': [{'streams': [{'input_number': 0, 'stream_number': 0, 'stream_type': 'video', 'language': None, 'default': True, 'size': [640, 360], 'bitrate': 97, 'fps': 59.95, 'codec_name': 'h264', 'profile': '(High)', 'metadata': {'Metadata': '', 'handler_name': 'VideoHandler', 'vendor_id': '[0][0][0][0]', 'encoder': 'Lavc61.3.100 libx264'}}, {'input_number': 0, 'stream_number': 1, 'stream_type': 'audio', 'language': None, 'default': True, 'fps': 44100, 'bitrate': 127, 'metadata': {'Metadata': '', 'handler_name': 'SoundHandler', 'vendor_id': '[0][0][0][0]'}}], 'input_number': 0}], 'duration': 64.94, 'bitrate': 238, 'start': 0.0, 'default_video_input_number': 0, 'default_video_stream_number': 0, 'video_codec_name': 'h264', 'video_profile': '(High)', 'video_size': [640, 360], 'video_bitrate': 97, 'video_fps': 59.95, 'default_audio_input_number': 0, 'default_audio_stream_number': 1, 'audio_fps': 44100, 'audio_bitrate': 127, 'video_duration': 64.94, 'video_n_frames': 3893}\n",
      "/opt/conda/lib/python3.10/site-packages/imageio_ffmpeg/binaries/ffmpeg-linux-x86_64-v7.0.2 -ss 48.040867 -i /var/tmp/tmpizxd0ub0/processed/room_camera_example.mp4 -ss 1.000000 -loglevel error -f image2pipe -vf scale=640:360 -sws_flags bicubic -pix_fmt rgb24 -vcodec rawvideo -\n",
      "{'video_found': True, 'audio_found': True, 'metadata': {'major_brand': 'isom', 'minor_version': '512', 'compatible_brands': 'isomiso2avc1mp41', 'encoder': 'Lavf61.1.100'}, 'inputs': [{'streams': [{'input_number': 0, 'stream_number': 0, 'stream_type': 'video', 'language': None, 'default': True, 'size': [640, 360], 'bitrate': 97, 'fps': 59.95, 'codec_name': 'h264', 'profile': '(High)', 'metadata': {'Metadata': '', 'handler_name': 'VideoHandler', 'vendor_id': '[0][0][0][0]', 'encoder': 'Lavc61.3.100 libx264'}}, {'input_number': 0, 'stream_number': 1, 'stream_type': 'audio', 'language': None, 'default': True, 'fps': 44100, 'bitrate': 127, 'metadata': {'Metadata': '', 'handler_name': 'SoundHandler', 'vendor_id': '[0][0][0][0]'}}], 'input_number': 0}], 'duration': 64.94, 'bitrate': 238, 'start': 0.0, 'default_video_input_number': 0, 'default_video_stream_number': 0, 'video_codec_name': 'h264', 'video_profile': '(High)', 'video_size': [640, 360], 'video_bitrate': 97, 'video_fps': 59.95, 'default_audio_input_number': 0, 'default_audio_stream_number': 1, 'audio_fps': 44100, 'audio_bitrate': 127, 'video_duration': 64.94, 'video_n_frames': 3893}\n",
      "/opt/conda/lib/python3.10/site-packages/imageio_ffmpeg/binaries/ffmpeg-linux-x86_64-v7.0.2 -i /var/tmp/tmpizxd0ub0/processed/room_camera_example.mp4 -loglevel error -f image2pipe -vf scale=640:360 -sws_flags bicubic -pix_fmt rgb24 -vcodec rawvideo -\n",
      "{'video_found': True, 'audio_found': True, 'metadata': {'major_brand': 'isom', 'minor_version': '512', 'compatible_brands': 'isomiso2avc1mp41', 'encoder': 'Lavf61.1.100'}, 'inputs': [{'streams': [{'input_number': 0, 'stream_number': 0, 'stream_type': 'video', 'language': None, 'default': True, 'size': [640, 360], 'bitrate': 97, 'fps': 59.95, 'codec_name': 'h264', 'profile': '(High)', 'metadata': {'Metadata': '', 'handler_name': 'VideoHandler', 'vendor_id': '[0][0][0][0]', 'encoder': 'Lavc61.3.100 libx264'}}, {'input_number': 0, 'stream_number': 1, 'stream_type': 'audio', 'language': None, 'default': True, 'fps': 44100, 'bitrate': 127, 'metadata': {'Metadata': '', 'handler_name': 'SoundHandler', 'vendor_id': '[0][0][0][0]'}}], 'input_number': 0}], 'duration': 64.94, 'bitrate': 238, 'start': 0.0, 'default_video_input_number': 0, 'default_video_stream_number': 0, 'video_codec_name': 'h264', 'video_profile': '(High)', 'video_size': [640, 360], 'video_bitrate': 97, 'video_fps': 59.95, 'default_audio_input_number': 0, 'default_audio_stream_number': 1, 'audio_fps': 44100, 'audio_bitrate': 127, 'video_duration': 64.94, 'video_n_frames': 3893}\n",
      "/opt/conda/lib/python3.10/site-packages/imageio_ffmpeg/binaries/ffmpeg-linux-x86_64-v7.0.2 -ss 19.000000 -i /var/tmp/tmpizxd0ub0/processed/room_camera_example.mp4 -ss 1.000000 -loglevel error -f image2pipe -vf scale=640:360 -sws_flags bicubic -pix_fmt rgb24 -vcodec rawvideo -\n",
      "{'video_found': True, 'audio_found': True, 'metadata': {'major_brand': 'isom', 'minor_version': '512', 'compatible_brands': 'isomiso2avc1mp41', 'encoder': 'Lavf61.1.100'}, 'inputs': [{'streams': [{'input_number': 0, 'stream_number': 0, 'stream_type': 'video', 'language': None, 'default': True, 'size': [640, 360], 'bitrate': 97, 'fps': 59.95, 'codec_name': 'h264', 'profile': '(High)', 'metadata': {'Metadata': '', 'handler_name': 'VideoHandler', 'vendor_id': '[0][0][0][0]', 'encoder': 'Lavc61.3.100 libx264'}}, {'input_number': 0, 'stream_number': 1, 'stream_type': 'audio', 'language': None, 'default': True, 'fps': 44100, 'bitrate': 127, 'metadata': {'Metadata': '', 'handler_name': 'SoundHandler', 'vendor_id': '[0][0][0][0]'}}], 'input_number': 0}], 'duration': 64.94, 'bitrate': 238, 'start': 0.0, 'default_video_input_number': 0, 'default_video_stream_number': 0, 'video_codec_name': 'h264', 'video_profile': '(High)', 'video_size': [640, 360], 'video_bitrate': 97, 'video_fps': 59.95, 'default_audio_input_number': 0, 'default_audio_stream_number': 1, 'audio_fps': 44100, 'audio_bitrate': 127, 'video_duration': 64.94, 'video_n_frames': 3893}\n",
      "/opt/conda/lib/python3.10/site-packages/imageio_ffmpeg/binaries/ffmpeg-linux-x86_64-v7.0.2 -i /var/tmp/tmpizxd0ub0/processed/room_camera_example.mp4 -loglevel error -f image2pipe -vf scale=640:360 -sws_flags bicubic -pix_fmt rgb24 -vcodec rawvideo -\n",
      "{'video_found': True, 'audio_found': True, 'metadata': {'major_brand': 'isom', 'minor_version': '512', 'compatible_brands': 'isomiso2avc1mp41', 'encoder': 'Lavf61.1.100'}, 'inputs': [{'streams': [{'input_number': 0, 'stream_number': 0, 'stream_type': 'video', 'language': None, 'default': True, 'size': [640, 360], 'bitrate': 97, 'fps': 59.95, 'codec_name': 'h264', 'profile': '(High)', 'metadata': {'Metadata': '', 'handler_name': 'VideoHandler', 'vendor_id': '[0][0][0][0]', 'encoder': 'Lavc61.3.100 libx264'}}, {'input_number': 0, 'stream_number': 1, 'stream_type': 'audio', 'language': None, 'default': True, 'fps': 44100, 'bitrate': 127, 'metadata': {'Metadata': '', 'handler_name': 'SoundHandler', 'vendor_id': '[0][0][0][0]'}}], 'input_number': 0}], 'duration': 64.94, 'bitrate': 238, 'start': 0.0, 'default_video_input_number': 0, 'default_video_stream_number': 0, 'video_codec_name': 'h264', 'video_profile': '(High)', 'video_size': [640, 360], 'video_bitrate': 97, 'video_fps': 59.95, 'default_audio_input_number': 0, 'default_audio_stream_number': 1, 'audio_fps': 44100, 'audio_bitrate': 127, 'video_duration': 64.94, 'video_n_frames': 3893}\n",
      "/opt/conda/lib/python3.10/site-packages/imageio_ffmpeg/binaries/ffmpeg-linux-x86_64-v7.0.2 -i /var/tmp/tmpizxd0ub0/processed/room_camera_example.mp4 -loglevel error -f image2pipe -vf scale=640:360 -sws_flags bicubic -pix_fmt rgb24 -vcodec rawvideo -\n",
      "{'video_found': True, 'audio_found': True, 'metadata': {'major_brand': 'isom', 'minor_version': '512', 'compatible_brands': 'isomiso2avc1mp41', 'encoder': 'Lavf61.1.100'}, 'inputs': [{'streams': [{'input_number': 0, 'stream_number': 0, 'stream_type': 'video', 'language': None, 'default': True, 'size': [640, 360], 'bitrate': 97, 'fps': 59.95, 'codec_name': 'h264', 'profile': '(High)', 'metadata': {'Metadata': '', 'handler_name': 'VideoHandler', 'vendor_id': '[0][0][0][0]', 'encoder': 'Lavc61.3.100 libx264'}}, {'input_number': 0, 'stream_number': 1, 'stream_type': 'audio', 'language': None, 'default': True, 'fps': 44100, 'bitrate': 127, 'metadata': {'Metadata': '', 'handler_name': 'SoundHandler', 'vendor_id': '[0][0][0][0]'}}], 'input_number': 0}], 'duration': 64.94, 'bitrate': 238, 'start': 0.0, 'default_video_input_number': 0, 'default_video_stream_number': 0, 'video_codec_name': 'h264', 'video_profile': '(High)', 'video_size': [640, 360], 'video_bitrate': 97, 'video_fps': 59.95, 'default_audio_input_number': 0, 'default_audio_stream_number': 1, 'audio_fps': 44100, 'audio_bitrate': 127, 'video_duration': 64.94, 'video_n_frames': 3893}\n",
      "/opt/conda/lib/python3.10/site-packages/imageio_ffmpeg/binaries/ffmpeg-linux-x86_64-v7.0.2 -ss 63.000000 -i /var/tmp/tmpizxd0ub0/processed/room_camera_example.mp4 -ss 1.000000 -loglevel error -f image2pipe -vf scale=640:360 -sws_flags bicubic -pix_fmt rgb24 -vcodec rawvideo -\n",
      "{'video_found': True, 'audio_found': True, 'metadata': {'major_brand': 'isom', 'minor_version': '512', 'compatible_brands': 'isomiso2avc1mp41', 'encoder': 'Lavf61.1.100'}, 'inputs': [{'streams': [{'input_number': 0, 'stream_number': 0, 'stream_type': 'video', 'language': None, 'default': True, 'size': [640, 360], 'bitrate': 97, 'fps': 59.95, 'codec_name': 'h264', 'profile': '(High)', 'metadata': {'Metadata': '', 'handler_name': 'VideoHandler', 'vendor_id': '[0][0][0][0]', 'encoder': 'Lavc61.3.100 libx264'}}, {'input_number': 0, 'stream_number': 1, 'stream_type': 'audio', 'language': None, 'default': True, 'fps': 44100, 'bitrate': 127, 'metadata': {'Metadata': '', 'handler_name': 'SoundHandler', 'vendor_id': '[0][0][0][0]'}}], 'input_number': 0}], 'duration': 64.94, 'bitrate': 238, 'start': 0.0, 'default_video_input_number': 0, 'default_video_stream_number': 0, 'video_codec_name': 'h264', 'video_profile': '(High)', 'video_size': [640, 360], 'video_bitrate': 97, 'video_fps': 59.95, 'default_audio_input_number': 0, 'default_audio_stream_number': 1, 'audio_fps': 44100, 'audio_bitrate': 127, 'video_duration': 64.94, 'video_n_frames': 3893}\n",
      "/opt/conda/lib/python3.10/site-packages/imageio_ffmpeg/binaries/ffmpeg-linux-x86_64-v7.0.2 -ss 48.000000 -i /var/tmp/tmpizxd0ub0/processed/room_camera_example.mp4 -ss 1.000000 -loglevel error -f image2pipe -vf scale=640:360 -sws_flags bicubic -pix_fmt rgb24 -vcodec rawvideo -\n",
      "Thread [04] - Adjust real_end_time from 2025-01-01 00:00:56 to 2025-01-01 00:00:57\n",
      "Thread [02] - Adjust real_end_time from 2025-01-01 00:00:36 to 2025-01-01 00:00:37\n",
      "Generating a summary text.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'summary': '暗い室内での不審人物の出没と行動',\n",
       " 'events': [{'real_start_time': '2025-01-01 00:00:00',\n",
       "   'real_end_time': '2025-01-01 00:00:20',\n",
       "   'status': 'usual',\n",
       "   'summary': '静止した暗い室内空間の継続。',\n",
       "   'details': '画像は暗い室内を示しており、左側には家具のシルエットが見えます。右側は壁またはドアです。期間中、シーンに目立った変化はなく、静止した状態が続いています。',\n",
       "   'scene_type': 'no_event',\n",
       "   'start_time': 0,\n",
       "   'end_time': 20},\n",
       "  {'real_start_time': '2025-01-01 00:00:20',\n",
       "   'real_end_time': '2025-01-01 00:00:37',\n",
       "   'status': 'unusual',\n",
       "   'summary': '暗闇の中で人物がカメラに顔を向ける不審な行動。',\n",
       "   'details': '暗い室内で、人物がドア付近に現れ、何かを操作しているように見えます。00:00:30頃に突然カメラの方を向き、顔がはっきりと映し出されました。その後、再びドア付近で動きが見られます。',\n",
       "   'start_time': 20,\n",
       "   'scene_type': 'event',\n",
       "   'end_time': 37},\n",
       "  {'real_start_time': '2025-01-01 00:00:37',\n",
       "   'real_end_time': '2025-01-01 00:00:49',\n",
       "   'status': 'usual',\n",
       "   'summary': '暗い室内で椅子の位置に変化がない状態。',\n",
       "   'details': '監視期間中、室内は暗く、左側に置かれた椅子に動きは見られませんでした。全体的に変化のない静止した状態が続いています。',\n",
       "   'scene_type': 'no_event',\n",
       "   'start_time': 37,\n",
       "   'end_time': 49},\n",
       "  {'real_start_time': '2025-01-01 00:00:49',\n",
       "   'real_end_time': '2025-01-01 00:00:57',\n",
       "   'status': 'unusual',\n",
       "   'summary': '暗闇の中、フードを被った人物が身をかがめて移動する不審な行動。',\n",
       "   'details': '非常に暗い室内で、フードを被った人物が身をかがめるようにして移動している。顔はほとんど見えないが、一瞬眼鏡をかけた顔が確認できる。不審な動きで、何かを探しているか、隠れようとしているように見える。',\n",
       "   'start_time': 49,\n",
       "   'scene_type': 'event',\n",
       "   'end_time': 57},\n",
       "  {'real_start_time': '2025-01-01 00:00:57',\n",
       "   'real_end_time': '2025-01-01 00:01:04',\n",
       "   'status': 'usual',\n",
       "   'summary': '暗い部屋で椅子の位置にわずかな変化が見られる期間',\n",
       "   'details': 'この期間中、暗い部屋の様子が捉えられています。左側にある椅子の位置にわずかな動きが見られますが、それ以外の大きな変化や特筆すべき出来事はありませんでした。全体的に静かで変化の少ない状態が続いています。',\n",
       "   'scene_type': 'no_event',\n",
       "   'start_time': 57,\n",
       "   'end_time': 64}]}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "analysis_result = analyze_events(\n",
    "    processed_video_path, video_start_time, merged_events,\n",
    "    language='Japanese', num_parallel=os.cpu_count()\n",
    ")\n",
    "analysis_result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e7f68d3-fe61-463a-9354-8a69cd9ebecd",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### ヒートマップで結果をビジュアライズ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9eacdf2c-02f8-46e6-b12e-46259da2fe04",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tmpfile = f'/tmp/tmp_movie_{uuid.uuid4()}.mp4'\n",
    "download_blob(processed_video_path, tmpfile)\n",
    "_ = show_heatmap(active_rate, analysis_result['events'])\n",
    "Video(tmpfile, embed=True, width=800)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4b5bfbc-3df7-418a-a708-597e93c16a18",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "conda-base-py",
   "name": "workbench-notebooks.m131",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/workbench-notebooks:m131"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel) (Local) (Local)",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
