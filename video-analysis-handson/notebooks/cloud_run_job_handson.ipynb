{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fc71e1c0-4997-4c1c-b7bc-adaba91e4040",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Gemini API とオープンソースによる動画処理・動画分析の手法"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14d1975a-702f-43bc-b539-28bcb292023c",
   "metadata": {},
   "source": [
    "このハンズオンでは、動画処理のタスクを Cloud Run Jobs にデプロイして、バッチジョブとして実行する方法を学びます。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b946fb68-ff33-42f9-9f7e-9a7d5f9319da",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 事前準備"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "553e2254-b552-45cd-8627-7f44686d0a7e",
   "metadata": {
    "tags": []
   },
   "source": [
    "### パッケージインストール"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b7a255bd-d55a-4471-949d-03d8a3796e20",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting google-cloud-run==0.10.17\n",
      "  Downloading google_cloud_run-0.10.17-py3-none-any.whl.metadata (9.3 kB)\n",
      "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1 in /opt/conda/lib/python3.10/site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-cloud-run==0.10.17) (2.25.1)\n",
      "Requirement already satisfied: google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1 in /opt/conda/lib/python3.10/site-packages (from google-cloud-run==0.10.17) (2.40.3)\n",
      "Requirement already satisfied: proto-plus<2.0.0,>=1.22.3 in /opt/conda/lib/python3.10/site-packages (from google-cloud-run==0.10.17) (1.26.1)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<7.0.0,>=3.20.2 in /opt/conda/lib/python3.10/site-packages (from google-cloud-run==0.10.17) (3.20.3)\n",
      "Requirement already satisfied: grpc-google-iam-v1<1.0.0,>=0.14.0 in /opt/conda/lib/python3.10/site-packages (from google-cloud-run==0.10.17) (0.14.2)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in /opt/conda/lib/python3.10/site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-cloud-run==0.10.17) (1.70.0)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.18.0 in /opt/conda/lib/python3.10/site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-cloud-run==0.10.17) (2.32.4)\n",
      "Requirement already satisfied: grpcio<2.0.0,>=1.33.2 in /opt/conda/lib/python3.10/site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-cloud-run==0.10.17) (1.73.1)\n",
      "Requirement already satisfied: grpcio-status<2.0.0,>=1.33.2 in /opt/conda/lib/python3.10/site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-cloud-run==0.10.17) (1.48.2)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-cloud-run==0.10.17) (5.5.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.10/site-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-cloud-run==0.10.17) (0.4.2)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.10/site-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-cloud-run==0.10.17) (4.9.1)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-cloud-run==0.10.17) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-cloud-run==0.10.17) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-cloud-run==0.10.17) (1.26.20)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-cloud-run==0.10.17) (2025.7.14)\n",
      "Requirement already satisfied: pyasn1>=0.1.3 in /opt/conda/lib/python3.10/site-packages (from rsa<5,>=3.1.4->google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-cloud-run==0.10.17) (0.6.1)\n",
      "Downloading google_cloud_run-0.10.17-py3-none-any.whl (332 kB)\n",
      "Installing collected packages: google-cloud-run\n",
      "Successfully installed google-cloud-run-0.10.17\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install google-cloud-run==0.10.17"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac400c90-54bf-44ed-b069-7d80a581b781",
   "metadata": {},
   "source": [
    "インストールしたパッケージを利用可能にするためにカーネルを再起動します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2d6674e7-3111-4b30-a7e9-84552e3dd50d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import IPython\n",
    "app = IPython.Application.instance()\n",
    "_ = app.kernel.do_shutdown(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec3b962a-d461-42e9-a349-7578bccad61b",
   "metadata": {
    "tags": []
   },
   "source": [
    "### モジュールのインポートと初期設定"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6a3eff5f-6c79-43ec-94fe-020ca7eacf2d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json, os, tempfile, uuid\n",
    "from IPython.display import Video\n",
    "from google.cloud import storage\n",
    "\n",
    "[PROJECT_ID] = !gcloud config list --format 'value(core.project)'\n",
    "[PROJECT_NUMBER] = !gcloud projects describe {PROJECT_ID} --format=\"value(projectNumber)\"\n",
    "LOCATION = 'us-central1'\n",
    "BUCKET_NAME = f'{PROJECT_ID}_video_files'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "672294ca-cfc4-4bc2-b714-5ebeb7102fec",
   "metadata": {},
   "source": [
    "### 補助関数の定義"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5a3d2f50-0408-4bab-9ca5-396c1938a3f6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def upload_blob(source_path, destination_path, bucket_name=BUCKET_NAME):\n",
    "    storage_client = storage.Client()\n",
    "    bucket = storage_client.bucket(bucket_name)\n",
    "    blob = bucket.blob(destination_path)\n",
    "    blob.upload_from_filename(source_path)\n",
    "    \n",
    "def download_blob(source_path, destination_path, bucket_name=BUCKET_NAME): \n",
    "    storage_client = storage.Client()\n",
    "    bucket = storage_client.bucket(bucket_name)\n",
    "    blob = bucket.blob(source_path)\n",
    "    blob.download_to_filename(destination_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c2ecd36-b8bd-4d9d-91a0-24ed92fdf163",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 動画の前処理タスクの実装"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b35abbc-fc4f-4d6e-a478-9cfddc37293e",
   "metadata": {
    "tags": []
   },
   "source": [
    "動画の前処理を行うコードを単一のファイルにまとめます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "16328f56-0a9b-4f42-ba30-ce3cde6c6a14",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "mkdir -p preprocess_job\n",
    "cd preprocess_job\n",
    "cat <<EOF >video_preprocessor.py\n",
    "import copy, json, os, pprint, sys, tempfile, threading, time, uuid\n",
    "import cv2\n",
    "from datetime import datetime, timedelta\n",
    "from tqdm import tqdm\n",
    "from moviepy import VideoFileClip, TextClip, CompositeVideoClip, VideoClip, ColorClip\n",
    "\n",
    "from google.cloud import storage\n",
    "from google import auth\n",
    "\n",
    "_, PROJECT_ID = auth.default()\n",
    "LOCATION = 'us-central1'\n",
    "BUCKET_NAME = f'{PROJECT_ID}_video_files'\n",
    "\n",
    "\n",
    "def upload_blob(source_path, destination_path, bucket_name=BUCKET_NAME):\n",
    "    storage_client = storage.Client()\n",
    "    bucket = storage_client.bucket(bucket_name)\n",
    "    blob = bucket.blob(destination_path)\n",
    "    blob.upload_from_filename(source_path)\n",
    "    \n",
    "\n",
    "def download_blob(source_path, destination_path, bucket_name=BUCKET_NAME): \n",
    "    storage_client = storage.Client()\n",
    "    bucket = storage_client.bucket(bucket_name)\n",
    "    blob = bucket.blob(source_path)\n",
    "    blob.download_to_filename(destination_path)\n",
    "\n",
    "\n",
    "def add_timestamp_overlay(\n",
    "    video_path,\n",
    "    output_path,\n",
    "    video_start_datetime='2025-01-01 00:00:00', \n",
    "):\n",
    "    with tempfile.TemporaryDirectory() as temp_dir:\n",
    "\n",
    "        video_source = os.path.join(temp_dir, video_path)\n",
    "        video_dest = os.path.join(temp_dir, output_path)\n",
    "\n",
    "        dirname, _ = os.path.split(video_source)\n",
    "        if dirname:\n",
    "            os.makedirs(dirname, exist_ok=True)\n",
    "        dirname, _ = os.path.split(video_dest)\n",
    "        if dirname:\n",
    "            os.makedirs(dirname, exist_ok=True)\n",
    "\n",
    "        download_blob(video_path, video_source)\n",
    "\n",
    "        # Parse the start time\n",
    "        start_datetime = datetime.strptime(\n",
    "            video_start_datetime, '%Y-%m-%d %H:%M:%S'\n",
    "        )\n",
    "\n",
    "        # Load video and resize it\n",
    "        video = VideoFileClip(video_source).resized(width=640)\n",
    "\n",
    "        # Background of timecode area\n",
    "        bg_clip = (\n",
    "            ColorClip(\n",
    "            size=(225, 38),   # Timecode area size\n",
    "            color=(0, 0, 0),  # Black color\n",
    "                duration=video.duration,\n",
    "            )\n",
    "            .with_opacity(0.5)\n",
    "            .with_position(('left', 'top'))\n",
    "        )\n",
    "\n",
    "        # Timecode clips\n",
    "        text_clips = []\n",
    "        total_seconds = int(video.duration)\n",
    "\n",
    "        for i in range(total_seconds + 1):\n",
    "            current_time = start_datetime + timedelta(seconds=i)\n",
    "            timestamp_text = current_time.strftime('%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "            clip_duration = 1.0\n",
    "            if i == total_seconds: # Last clip might be shorter\n",
    "                clip_duration = video.duration - total_seconds\n",
    "                if clip_duration <= 0:\n",
    "                    continue\n",
    "\n",
    "            txt = (\n",
    "                TextClip(\n",
    "                    text=timestamp_text,\n",
    "                    font_size=19,\n",
    "                    color='white',\n",
    "                    font='DejaVuSans',\n",
    "                    method='label',\n",
    "               )\n",
    "               .with_duration(clip_duration)\n",
    "               .with_start(i)\n",
    "               .with_position((10, 12))\n",
    "            )\n",
    "            text_clips.append(txt)\n",
    "\n",
    "        # Merge all clips\n",
    "        all_clips = [video, bg_clip] + text_clips\n",
    "        final_video = CompositeVideoClip(all_clips)\n",
    "\n",
    "        # Write the result with optimized settings\n",
    "        if video.audio is None:\n",
    "            final_video.write_videofile(\n",
    "                video_dest,\n",
    "                codec='libx264',\n",
    "                preset='faster',\n",
    "                threads=os.cpu_count(),\n",
    "                audio=False,\n",
    "                remove_temp=True,\n",
    "                # logger=None,  # Suppress moviepy's verbose output\n",
    "            )\n",
    "        else:\n",
    "            with tempfile.TemporaryDirectory() as temp_dir:\n",
    "                final_video.write_videofile(\n",
    "                  video_dest,\n",
    "                  codec='libx264',\n",
    "                  preset='faster',\n",
    "                  threads=os.cpu_count(),\n",
    "                  audio_codec='libvorbis',\n",
    "                  # temp_audiofile should be in tmpdir\n",
    "                  temp_audiofile=os.path.join(temp_dir, 'temp-audio.ogg'),\n",
    "                  remove_temp=True,\n",
    "                  # logger=None,  # Suppress moviepy's verbose output\n",
    "                )\n",
    "\n",
    "        upload_blob(video_dest, output_path)\n",
    "        \n",
    "        # Cleanup\n",
    "        for item in all_clips:\n",
    "            item.close()\n",
    "        final_video.close()\n",
    "\n",
    "    return video_start_datetime\n",
    "\n",
    "\n",
    "def detect_motion_events(video_path):\n",
    "    sampling_fps = 1\n",
    "    mog2_history = 500\n",
    "    mog2_var_threshold = 16\n",
    "    \n",
    "    with tempfile.TemporaryDirectory() as temp_dir:\n",
    "        video_source = os.path.join(temp_dir, video_path)\n",
    "        dirname, _ = os.path.split(video_source)\n",
    "        if dirname:\n",
    "            os.makedirs(dirname, exist_ok=True)\n",
    "        download_blob(video_path, video_source)\n",
    "        \n",
    "        cap = cv2.VideoCapture(video_source)\n",
    "\n",
    "        fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "        assert(sampling_fps <= fps)\n",
    "        frame_skip_interval = max(1, int(round(fps / sampling_fps)))\n",
    "        print(\n",
    "            f\"Video FPS: {fps}, Sampling FPS: {sampling_fps}, Frame Skip Interval: {frame_skip_interval}\"\n",
    "        )\n",
    "\n",
    "        # Initialize MOG2 background subtractor\n",
    "        fgbg_mog2 = cv2.createBackgroundSubtractorMOG2(\n",
    "            history=mog2_history, varThreshold=mog2_var_threshold, detectShadows=True\n",
    "        )\n",
    "\n",
    "        mog2_motion_timestamps = []\n",
    "        active_rate_list = []\n",
    "        frame_count = -1\n",
    "        kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (5, 5))\n",
    "        total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "\n",
    "        for _ in tqdm(\n",
    "            range(total_frames), desc=\"Processing video frames\", unit=\"frames\"\n",
    "        ):\n",
    "            frame_count += 1\n",
    "            ret, frame = cap.read()\n",
    "            if not ret:\n",
    "                break\n",
    "\n",
    "            # Process with sampling_fps\n",
    "            if frame_count % frame_skip_interval != 0:\n",
    "                continue\n",
    "\n",
    "            # Apply MOG2 to get foreground mask\n",
    "            fgmask_mog2 = fgbg_mog2.apply(frame)\n",
    "            fgmask_mog2 = cv2.morphologyEx(fgmask_mog2, cv2.MORPH_OPEN, kernel)\n",
    "            fgmask_mog2 = cv2.morphologyEx(fgmask_mog2, cv2.MORPH_CLOSE, kernel)\n",
    "\n",
    "            # Check if moving objects occupy more than 0.5% of the entire screen\n",
    "            mog2_motion_pixels = cv2.countNonZero(fgmask_mog2)\n",
    "            active_rate = (mog2_motion_pixels * 100) / (frame.shape[0] * frame.shape[1])\n",
    "            current_time = frame_count / fps\n",
    "\n",
    "            if active_rate > 0.5:\n",
    "                mog2_motion_timestamps.append(current_time)\n",
    "\n",
    "            if current_time == 0:\n",
    "                active_rate = 0\n",
    "            active_rate_list.append(active_rate)\n",
    "\n",
    "        cap.release()\n",
    "        video_duration = total_frames / fps if fps > 0 else 0.0\n",
    "\n",
    "    return {\n",
    "        \"video_duration\": video_duration,\n",
    "        \"event_timestamp\": mog2_motion_timestamps,\n",
    "        \"active_rate\": active_rate_list,\n",
    "    }\n",
    "\n",
    "\n",
    "def analyze_motion_intervals(\n",
    "        mog2_motion_timestamps,\n",
    "        video_duration,\n",
    "        time_threshold=1.5,\n",
    "        min_event_duration=3.0,\n",
    "        max_event_duration=180.0,\n",
    "):\n",
    "    assert min_event_duration < max_event_duration\n",
    "\n",
    "    def add_event(event_list, start_time, end_time, event_type):\n",
    "        # The main logic should append event periods consecutively.\n",
    "        assert start_time <= end_time\n",
    "        if event_list:\n",
    "            assert event_list[-1]['end_time'] == start_time\n",
    "        else:\n",
    "            assert start_time == 0\n",
    "\n",
    "        # Ignore if start_time == end_time\n",
    "        if start_time == end_time:\n",
    "            return\n",
    "\n",
    "        # Join consecutive no_event periods\n",
    "        if (\n",
    "            event_type == 'no_event'\n",
    "            and event_list\n",
    "            and event_list[-1]['type'] == 'no_event'\n",
    "        ):\n",
    "            event_list[-1]['end_time'] = end_time\n",
    "            return\n",
    "\n",
    "        # Add an event period\n",
    "        event_list.append(\n",
    "            {'start_time': start_time, 'end_time': end_time, 'type': event_type}\n",
    "        )\n",
    "        return\n",
    "\n",
    "    event_intervals = []\n",
    "    timestamps = copy.copy(mog2_motion_timestamps)\n",
    "    current_start_time = current_end_time = 0\n",
    "\n",
    "    while timestamps:\n",
    "        event_timestamp = timestamps.pop(0)\n",
    "        if (\n",
    "            event_timestamp - current_end_time <= time_threshold\n",
    "        ):  # Event is continuing\n",
    "            current_end_time = event_timestamp\n",
    "            if (\n",
    "                timestamps\n",
    "                and current_end_time - current_start_time < max_event_duration\n",
    "            ):\n",
    "                continue\n",
    "\n",
    "        # Now split events as:\n",
    "        #   A. (current_start_time, current_end_time): event (or no_event if event_duration < min_event_duration)\n",
    "        #   B. (current_end_time, event_timestamp): no_event\n",
    "\n",
    "        # Add A.\n",
    "        event_duration = current_end_time - current_start_time\n",
    "        if (\n",
    "            event_intervals and event_intervals[-1]['type'] == 'event'\n",
    "        ):  # Event is continuing\n",
    "            if (\n",
    "                event_duration < 5\n",
    "            ):  # Extend the last event if the current event period is too short\n",
    "                event_intervals[-1]['end_time'] = current_end_time\n",
    "            else:\n",
    "                add_event(\n",
    "                    event_intervals, current_start_time, current_end_time, 'event'\n",
    "                )\n",
    "        elif event_duration >= min_event_duration:\n",
    "            add_event(\n",
    "                event_intervals, current_start_time, current_end_time, 'event'\n",
    "            )\n",
    "        else:\n",
    "            add_event(\n",
    "                event_intervals, current_start_time, current_end_time, 'no_event'\n",
    "            )\n",
    "\n",
    "        # Add B.\n",
    "        add_event(event_intervals, current_end_time, event_timestamp, 'no_event')\n",
    "\n",
    "        current_start_time = current_end_time = event_timestamp\n",
    "\n",
    "    # Add the final no_event (or maybe event) period until the end of the video.\n",
    "    if (event_intervals[-1]['type']=='event' and\n",
    "        video_duration - current_end_time <= time_threshold):\n",
    "        event_intervals[-1]['end_time'] = video_duration\n",
    "    else:\n",
    "        add_event(event_intervals, current_end_time, video_duration, 'no_event')            \n",
    "\n",
    "    return event_intervals\n",
    "\n",
    "\n",
    "def detect_events(\n",
    "    video_path,\n",
    "    video_path_ts_overlay,\n",
    "    video_start_datetime='2025-01-01 00:00:00'\n",
    "):\n",
    "    print(f'# Preprocess: {video_path}')\n",
    "    add_timestamp_overlay(video_path, video_path_ts_overlay, video_start_datetime)\n",
    "    print(f'# Detect events: {video_path_ts_overlay}')\n",
    "    motion_events = detect_motion_events(video_path_ts_overlay)     \n",
    "    merged_events = analyze_motion_intervals(\n",
    "        motion_events.get('event_timestamp'),\n",
    "        motion_events.get(\"video_duration\"),\n",
    "    )\n",
    "    active_rate = motion_events.get('active_rate')\n",
    "\n",
    "    return {\n",
    "        'video_path_ts_overlay': video_path_ts_overlay,\n",
    "        'video_start_datetime': video_start_datetime,\n",
    "        'merged_events': merged_events,\n",
    "        'active_rate': active_rate,\n",
    "    }\n",
    "\n",
    "#####\n",
    "\n",
    "def start_job():\n",
    "    gcs_payload_uri = os.environ.get(\"GCS_PAYLOAD_URI\")\n",
    "    json_payload_string = None\n",
    "\n",
    "    if not gcs_payload_uri:\n",
    "        print(\"GCS_PAYLOAD_URI environment variable not found. Cannot load job payload.\")\n",
    "        sys.exit(1)\n",
    "\n",
    "    print(f\"Attempting to download payload from: {gcs_payload_uri}\")\n",
    "    try:\n",
    "        if not gcs_payload_uri.startswith(f\"gs://{BUCKET_NAME}/\"):\n",
    "            print(f\"GCS_PAYLOAD_URI is not in the expected format or bucket. URI: {gcs_payload_uri}\")\n",
    "            sys.exit(1)\n",
    "        \n",
    "        blob_name = gcs_payload_uri.split(f\"gs://{BUCKET_NAME}/\", 1)[1]\n",
    "        storage_client = storage.Client()\n",
    "        bucket = storage_client.bucket(BUCKET_NAME)\n",
    "        blob = bucket.blob(blob_name)\n",
    "        json_payload_string = blob.download_as_text()\n",
    "\n",
    "        if json_payload_string is False:\n",
    "            print(f\"Failed to download payload from GCS URI: {gcs_payload_uri}\")\n",
    "            sys.exit(1)\n",
    "        if not json_payload_string:\n",
    "            print(f\"Downloaded payload from GCS is empty. URI: {gcs_payload_uri}\")\n",
    "            sys.exit(1)\n",
    "            \n",
    "        print(f\"Successfully downloaded and read payload from {gcs_payload_uri}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error downloading or processing payload from GCS URI {gcs_payload_uri}: {e}\", exc_info=True)\n",
    "        sys.exit(1)\n",
    "\n",
    "    try:\n",
    "        input_data = json.loads(json_payload_string)\n",
    "        event_type = input_data[\"event_type\"]\n",
    "        job_id = input_data[\"job_id\"]\n",
    "        analysis_request = input_data['analysis_request']\n",
    " \n",
    "        print(f\"Event type: {event_type}\")\n",
    "        print(f\"Job id: {job_id}\")\n",
    "        print(f\"Analysis request: {analysis_request}\")\n",
    "\n",
    "        if event_type == \"video_preprocess\":\n",
    "            video_path = analysis_request[\"video_path\"]\n",
    "            video_path_ts_overlay = analysis_request[\"video_path_ts_overlay\"]\n",
    "            video_start_datetime = analysis_request[\"video_start_datetime\"]\n",
    "            \n",
    "            ret = detect_events(\n",
    "                video_path,\n",
    "                video_path_ts_overlay,\n",
    "                video_start_datetime=video_start_datetime\n",
    "            )\n",
    "\n",
    "            if not ret:\n",
    "                print(f\"Video analysis job is failed\")\n",
    "                sys.exit(1)\n",
    "        else:\n",
    "            print(f\"Not supported event type: {event_type}\")\n",
    "            sys.exit(1)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error at executing job: {e}\", exc_info=True)\n",
    "        sys.exit(1)\n",
    "\n",
    "\n",
    "    print(\"Success to process long-running job ...\")\n",
    "    sys.exit(0)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    start_job()\n",
    "EOF"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8224e39a-5b2b-4bd9-8a44-5c65123fe374",
   "metadata": {},
   "source": [
    "### 実行例"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d2e8323-ca9e-4a0b-8f90-3abd2737c641",
   "metadata": {
    "tags": []
   },
   "source": [
    "このコードは、リクエスト内容を記述した JSON ファイルを GCS バケットに保存して実行します。\n",
    "\n",
    "次は、リクエストファイルを作成して、該当ファイルの URI を環境変数 `GCS_PAYLOAD_URI` にセットしています。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a482e37b-9f2c-4b89-bbd3-3344152bd1b9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "job_id = str(uuid.uuid4())\n",
    "request_file = f'{job_id}.json'\n",
    "gcs_payload_uri = f'gs://{BUCKET_NAME}/job_request/{request_file}'\n",
    "\n",
    "os.environ['GCS_PAYLOAD_URI'] = gcs_payload_uri\n",
    "\n",
    "request_content = {\n",
    "    'event_type': 'video_preprocess',\n",
    "    'job_id': job_id,\n",
    "    'analysis_request': {\n",
    "        'video_path': 'original/room_camera_example.mov',\n",
    "        'video_path_ts_overlay': 'processed/room_camera_example.mp4',\n",
    "        'video_start_datetime': '2025-01-01 12:30:00',\n",
    "    },\n",
    "}\n",
    "\n",
    "with tempfile.TemporaryDirectory() as temp_dir:\n",
    "    tmp_request_file = os.path.join(temp_dir, request_file)\n",
    "    with open(tmp_request_file, 'wt') as f:\n",
    "        f.write(json.dumps(request_content))\n",
    "    upload_blob(tmp_request_file, f'job_request/{request_file}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51567abd-f722-4ff7-8d50-3b0f9986370c",
   "metadata": {
    "tags": []
   },
   "source": [
    "既存の前処理済みファイル `room_camera_example.mp4` を削除しておきます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5f54c415-e092-4823-b63b-a588b40a6a06",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removing gs://video-analysis-handson00_video_files/processed/room_camera_example.mp4...\n",
      "/ [1 objects]                                                                   \n",
      "Operation completed over 1 objects.                                              \n",
      "CommandException: One or more URLs matched no objects.\n"
     ]
    }
   ],
   "source": [
    "!gsutil rm gs://{BUCKET_NAME}/processed/room_camera_example.mp4\n",
    "!gsutil ls -l gs://{BUCKET_NAME}/processed/room_camera_example.mp4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b4f4eba-921c-46eb-bdb1-a217a7aa2b4f",
   "metadata": {},
   "source": [
    "この状態でコードを実行すると、リクエストファイルに従った処理が行われます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "33308be1-8ce6-4626-8b16-2cc219948d61",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gs://video-analysis-handson00_video_files/job_request/9b2e868b-0640-465d-ac61-246330e3646d.json\n",
      "Attempting to download payload from: gs://video-analysis-handson00_video_files/job_request/9b2e868b-0640-465d-ac61-246330e3646d.json\n",
      "Successfully downloaded and read payload from gs://video-analysis-handson00_video_files/job_request/9b2e868b-0640-465d-ac61-246330e3646d.json\n",
      "Event type: video_preprocess\n",
      "Job id: 9b2e868b-0640-465d-ac61-246330e3646d\n",
      "Analysis request: {'video_path': 'original/room_camera_example.mov', 'video_path_ts_overlay': 'processed/room_camera_example.mp4', 'video_start_datetime': '2025-01-01 12:30:00'}\n",
      "# Preprocess: original/room_camera_example.mov\n",
      "{'video_found': True, 'audio_found': True, 'metadata': {'major_brand': 'qt', 'minor_version': '0', 'compatible_brands': 'qt', 'creation_time': '2025-07-27T00:24:34.000000Z', 'com.apple.quicktime.make': 'Apple', 'com.apple.quicktime.model': 'Mac15,12', 'com.apple.quicktime.software': 'macOS 15.5 (24F74)', 'com.apple.quicktime.creationdate': '2025-07-27T09:21:08+0900'}, 'inputs': [{'streams': [{'input_number': 0, 'stream_number': 0, 'stream_type': 'video', 'language': None, 'default': True, 'size': [1280, 720], 'bitrate': 5564, 'fps': 59.95, 'codec_name': 'h264', 'profile': '(Main)', 'metadata': {'Metadata': '', 'creation_time': '2025-07-27T00:24:34.000000Z', 'handler_name': 'Core Media Video', 'vendor_id': '[0][0][0][0]', 'encoder': 'H.264'}}, {'input_number': 0, 'stream_number': 1, 'stream_type': 'audio', 'language': None, 'default': True, 'fps': 48000, 'bitrate': 255, 'metadata': {'Metadata': '', 'creation_time': '2025-07-27T00:24:34.000000Z', 'handler_name': 'Core Media Audio', 'vendor_id': '[0][0][0][0]'}}], 'input_number': 0}], 'duration': 64.94, 'bitrate': 5840, 'start': 0.0, 'default_video_input_number': 0, 'default_video_stream_number': 0, 'video_codec_name': 'h264', 'video_profile': '(Main)', 'video_size': [1280, 720], 'video_bitrate': 5564, 'video_fps': 59.95, 'default_audio_input_number': 0, 'default_audio_stream_number': 1, 'audio_fps': 48000, 'audio_bitrate': 255, 'video_duration': 64.94, 'video_n_frames': 3893}\n",
      "/opt/conda/lib/python3.10/site-packages/imageio_ffmpeg/binaries/ffmpeg-linux-x86_64-v7.0.2 -i /var/tmp/tmpejqe6c68/original/room_camera_example.mov -loglevel error -f image2pipe -vf scale=1280:720 -sws_flags bicubic -pix_fmt rgb24 -vcodec rawvideo -\n",
      "MoviePy - Building video /var/tmp/tmpejqe6c68/processed/room_camera_example.mp4.\n",
      "MoviePy - Writing audio in /var/tmp/tmpz_pcjfo4/temp-audio.ogg\n",
      "MoviePy - Done.\n",
      "MoviePy - Writing video /var/tmp/tmpejqe6c68/processed/room_camera_example.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "frame_index:  67%|██████▋   | 2607/3893 [01:29<00:43, 29.43it/s, now=None]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done !\n",
      "MoviePy - video ready /var/tmp/tmpejqe6c68/processed/room_camera_example.mp4\n",
      "# Detect events: processed/room_camera_example.mp4\n",
      "Video FPS: 59.95, Sampling FPS: 1, Frame Skip Interval: 60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing video frames: 100%|██████████| 3893/3893 [00:01<00:00, 3725.64frames/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success to process long-running job ...\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "echo $GCS_PAYLOAD_URI\n",
    "python preprocess_job/video_preprocessor.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c6a7bc99-6f74-446b-9eb6-faa2ee60788b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   1445927  2025-07-27T04:32:38Z  gs://video-analysis-handson00_video_files/processed/room_camera_example.mp4\n",
      "TOTAL: 1 objects, 1445927 bytes (1.38 MiB)\n"
     ]
    }
   ],
   "source": [
    "!gsutil ls -l gs://{BUCKET_NAME}/processed/room_camera_example.mp4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30744c03-2ba1-4e07-ad7e-4757ee8b73a7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "processed_video_path = f'processed/room_camera_example.mp4'\n",
    "tmpfile = f'/tmp/tmp_movie_{uuid.uuid4()}.mp4'\n",
    "download_blob(processed_video_path, tmpfile)\n",
    "Video(tmpfile, embed=True, width=480)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53582c40-becd-463c-8c61-01a4a517ecdb",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Croud Run Jobs へのデプロイ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b975ece2-9d8e-4741-bfbb-adb20ecb7601",
   "metadata": {
    "tags": []
   },
   "source": [
    "`Docerfile` と `requirements.txt` を用意します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bc3712d0-c968-4d06-a569-419e9998431d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "cd preprocess_job\n",
    "cat <<EOF >Dockerfile\n",
    "FROM python:3.12-slim\n",
    "\n",
    "# Packages for OpenCV\n",
    "RUN apt-get update && apt-get install -y \\\n",
    "    libgl1-mesa-glx \\\n",
    "    libglib2.0-0 \\\n",
    "    fontconfig \\\n",
    "    fonts-dejavu \\\n",
    "    && rm -rf /var/lib/apt/lists/*\n",
    "\n",
    "WORKDIR /app\n",
    "\n",
    "COPY requirements.txt ./\n",
    "RUN pip install --no-cache-dir -r requirements.txt\n",
    "\n",
    "COPY . .\n",
    "\n",
    "CMD [\"python\", \"video_preprocessor.py\"]\n",
    "EOF\n",
    "\n",
    "cat <<EOF >requirements.txt\n",
    "fastapi[all]==0.115.12\n",
    "loguru==0.7.3\n",
    "requests==2.32.3\n",
    "grpcio==1.67.1\n",
    "grpcio-status==1.67.1\n",
    "python-jose==3.3.0\n",
    "passlib==1.7.4\n",
    "msgspec==0.19.0\n",
    "\n",
    "# GCP dependency\n",
    "google-cloud-logging==3.12.1\n",
    "google-cloud-run==0.10.17\n",
    "google-cloud-storage==2.14.0\n",
    "\n",
    "# Used for Video rendering\n",
    "opencv-python==4.11.0.86\n",
    "moviepy==2.1.2\n",
    "tqdm==4.67.1\n",
    "EOF"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "156797b7-8390-48ba-af11-91fbd2776f30",
   "metadata": {},
   "source": [
    "ビルド用のリポジトリを作成します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ecaf39e1-e117-41eb-9067-dacd85621036",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create request issued for: [cloud-run-source-deploy]\n",
      "Waiting for operation [projects/video-analysis-handson00/locations/us-central1/\n",
      "operations/bc2f13bd-6171-48d7-a5a1-3f08f677610f] to complete...done.           \n",
      "Created repository [cloud-run-source-deploy].\n"
     ]
    }
   ],
   "source": [
    "REPO_NAME = 'cloud-run-source-deploy'\n",
    "REPO = f'{LOCATION}-docker.pkg.dev/{PROJECT_ID}/{REPO_NAME}'\n",
    "\n",
    "result = !gcloud artifacts repositories describe --location {LOCATION} {REPO_NAME}\n",
    "if result and result[0].startswith('ERROR: '):\n",
    "    !gcloud artifacts repositories create {REPO_NAME} \\\n",
    "        --repository-format docker --location {LOCATION}\n",
    "\n",
    "JOB_NAME = 'video-preprocess-job'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67de57f6-b9a9-4798-8da2-1e9b14b2ac67",
   "metadata": {},
   "source": [
    "コンテナイメージをビルドして、Cloud Run Jobs にデプロイします。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1c173b3-4f91-44c6-8a1a-798111b4e3e4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!cd preprocess_job && gcloud builds submit --tag {REPO}/{JOB_NAME}\n",
    "!gcloud run jobs deploy {JOB_NAME} \\\n",
    "    --image {REPO}/{JOB_NAME} \\\n",
    "    --region us-central1 \\\n",
    "    --task-timeout 3600s \\\n",
    "    --cpu=4 \\\n",
    "    --memory=8Gi | cat"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa811206-9c8e-4a97-84b1-3232d3a75392",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 実行例"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fff9382-0b8b-411c-9dd1-b5ea4db36432",
   "metadata": {},
   "source": [
    "既存の前処理済みファイル `room_camera_example.mp4` を削除しておきます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "93e7e425-8c83-445a-b1d8-fe386679a3fd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removing gs://video-analysis-handson00_video_files/processed/room_camera_example.mp4...\n",
      "/ [1 objects]                                                                   \n",
      "Operation completed over 1 objects.                                              \n",
      "CommandException: One or more URLs matched no objects.\n"
     ]
    }
   ],
   "source": [
    "!gsutil rm gs://{BUCKET_NAME}/processed/room_camera_example.mp4\n",
    "!gsutil ls -l gs://{BUCKET_NAME}/processed/room_camera_example.mp4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed7fc565-6524-44f8-9b96-38376841c9c9",
   "metadata": {},
   "source": [
    "次のように、`RunJobRequest.Overrides()` で環境変数の値をセットしてジョブの実行をリクエストします。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b06a529a-1ad9-494e-8904-98d0bef7bd87",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "name: \"projects/video-analysis-handson00/locations/us-central1/jobs/video-preprocess-job/executions/video-preprocess-job-vlg4b\"\n",
       "uid: \"40c5d398-5b80-4ef6-bac1-9eb8c4599da0\"\n",
       "generation: 1\n",
       "create_time {\n",
       "  seconds: 1753591078\n",
       "  nanos: 921655000\n",
       "}\n",
       "update_time {\n",
       "  seconds: 1753591078\n",
       "  nanos: 921655000\n",
       "}\n",
       "launch_stage: GA\n",
       "job: \"video-preprocess-job\"\n",
       "parallelism: 1\n",
       "task_count: 1\n",
       "template {\n",
       "  containers {\n",
       "    image: \"us-central1-docker.pkg.dev/video-analysis-handson00/cloud-run-source-deploy/video-preprocess-job\"\n",
       "    env {\n",
       "      name: \"GCS_PAYLOAD_URI\"\n",
       "      value: \"gs://video-analysis-handson00_video_files/job_request/9b2e868b-0640-465d-ac61-246330e3646d.json\"\n",
       "    }\n",
       "    resources {\n",
       "      limits {\n",
       "        key: \"cpu\"\n",
       "        value: \"4\"\n",
       "      }\n",
       "      limits {\n",
       "        key: \"memory\"\n",
       "        value: \"8Gi\"\n",
       "      }\n",
       "    }\n",
       "  }\n",
       "  max_retries: 3\n",
       "  timeout {\n",
       "    seconds: 3600\n",
       "  }\n",
       "  service_account: \"127334181968-compute@developer.gserviceaccount.com\"\n",
       "  execution_environment: EXECUTION_ENVIRONMENT_GEN2\n",
       "}\n",
       "reconciling: true\n",
       "conditions {\n",
       "  type_: \"Completed\"\n",
       "  state: CONDITION_PENDING\n",
       "}\n",
       "log_uri: \"https://console.cloud.google.com/logs/viewer?project=video-analysis-handson00&advancedFilter=resource.type%3D%22cloud_run_job%22%0Aresource.labels.job_name%3D%22video-preprocess-job%22%0Aresource.labels.location%3D%22us-central1%22%0Alabels.%22run.googleapis.com/execution_name%22%3D%22video-preprocess-job-vlg4b%22\"\n",
       "creator: \"127334181968-compute@developer.gserviceaccount.com\"\n",
       "etag: \"\\\"CKbalsQGENitvbcD/cHJvamVjdHMvdmlkZW8tYW5hbHlzaXMtaGFuZHNvbjAwL2xvY2F0aW9ucy91cy1jZW50cmFsMS9qb2JzL3ZpZGVvLXByZXByb2Nlc3Mtam9iL2V4ZWN1dGlvbnMvdmlkZW8tcHJlcHJvY2Vzcy1qb2ItdmxnNGI\\\"\""
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from google.cloud.run_v2.services.jobs import JobsClient\n",
    "from google.cloud.run_v2.types import RunJobRequest\n",
    "\n",
    "gcs_payload_uri = f'gs://{BUCKET_NAME}/job_request/{request_file}'\n",
    "overrides = RunJobRequest.Overrides(\n",
    "    container_overrides=[\n",
    "        RunJobRequest.Overrides.ContainerOverride(\n",
    "            env=[\n",
    "                {\"name\": \"GCS_PAYLOAD_URI\", \"value\": gcs_payload_uri},\n",
    "            ],\n",
    "        )\n",
    "    ]\n",
    ")\n",
    "\n",
    "job_path = f'projects/{PROJECT_ID}/locations/{LOCATION}/jobs/{JOB_NAME}'\n",
    "request = RunJobRequest(name=job_path, overrides=overrides)\n",
    "operation = JobsClient().run_job(request=request)\n",
    "operation.metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8189360e-2b4a-4940-8431-8f01a7d900c6",
   "metadata": {
    "tags": []
   },
   "source": [
    "Cloud Console の Cloud Run Jobs [管理ページ](https://console.cloud.google.com/run/jobs) からジョブの実行状況を確認してください。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "101d5495-9d75-4a67-8894-3a4ebe798aea",
   "metadata": {},
   "source": [
    "## 演習課題"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d075b2e-1c0c-49ca-898b-b6788119774e",
   "metadata": {
    "tags": []
   },
   "source": [
    "Cloud Run Jobs を用いて、動画の前処理に加えて、Gemini API による分析処理も行えるように実装してください。"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "conda-base-py",
   "name": "workbench-notebooks.m131",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/workbench-notebooks:m131"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel) (Local)",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
